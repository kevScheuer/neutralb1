{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdea8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import neutralb1.utils as utils\n",
    "\n",
    "WORKSPACE_DIR = utils.get_workspace_dir()\n",
    "\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=WORKSPACE_DIR).decode('utf-8').strip()\n",
    "print(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de87726",
   "metadata": {},
   "source": [
    "**Repository Version** \n",
    "This notebook was run at commit:\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fa8df",
   "metadata": {},
   "source": [
    "# Input-Output Test\n",
    "Previous input-output tests were done with the old DSelector event selection, so we need to repeat the I/O study with our new FSRoot-based event selection. We'll also reduce the binning to 10 MeV to match that of data, but we'll need to integrate over the entire $0.1\\leq -t \\leq 1.0$ range due to the lack of statistics for this signal MC dataset. This is safe to do, as there is no t-dependent physics generated in the dataset aside from an exponential curve, so binning finer in $-t$ only changes the statistics. The signal MC was generated with the following waveset:\n",
    "* $b_1(1235)$ and $\\rho(1450)$ Breit-Wigners fixed to their PDG values\n",
    "  * an isotropic background is included, but is so small it's negligible\n",
    "* No `OmegaDalitz` amplitudes for changing the dalitz distribution of the $\\omega$ and its corresponding $\\lambda$ distribution\n",
    "* No $D/S$ ratio that would be typically associated with the $b_1$\n",
    "* Only in the PARA 0 orientation\n",
    "\n",
    "We mimic the waveset here, but will be doing a mass-independent fit, so no Breit-Wigner terms are used. The goal of this notebook is to see if any of our fits, after having passed through detector simulation and event selection, significantly fail to find the true values we generated. See the associated analysis note for details on how we extract the truth information from the generated data to compare to for our mass-independent fits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6923d32",
   "metadata": {},
   "source": [
    "Most bins were performed with 100 randomized fits and 100 bootstrap fits. Some bins above 1.5 GeV required more than 100 randomized fits to have a successfully converged one. Two bins currently unfortunately fail to converge even with 5000 randomized fit attempts, though they are significantly above the generated amplitudes such that difficulties measuring them is to be expected. Fits are performed in 10 MeV mass-independent bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load common libraries\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import pathlib\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict\n",
    "\n",
    "# load neutralb1 libraries\n",
    "import neutralb1.utils as utils\n",
    "from neutralb1.analysis.result import ResultManager\n",
    "import neutralb1.analysis.statistics as stats\n",
    "\n",
    "utils.load_environment()\n",
    "\n",
    "# load in useful directories as constants\n",
    "CWD = pathlib.Path.cwd()\n",
    "STUDY_DIR = f\"{WORKSPACE_DIR}/studies/io-tests/thin-bins/\"\n",
    "\n",
    "# set env variables for shell cells\n",
    "os.environ[\"WORKSPACE_DIR\"] = WORKSPACE_DIR\n",
    "os.environ['STUDY_DIR'] = STUDY_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2f7f2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# print out yaml file used to submit the fits\n",
    "cat $STUDY_DIR/submission.YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c56bc3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# print out truth YAML file used to submit truth fits\n",
    "cat $STUDY_DIR/truth_submission.YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b755b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in preprocessed results\n",
    "with open(f\"{STUDY_DIR}/t_0.1-1.0/preprocessed_results.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "    results = ResultManager(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06b00e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9425bc",
   "metadata": {},
   "source": [
    "### Standard Plots\n",
    "Lets view the standard set of plots to view how our model performed overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.intensity.jp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c67cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.intensity.waves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf11d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.intensity.waves(fractional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97522f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.diagnostic.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot.intensity.moments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also make a quick plot of just the truth lines of the JP plot, for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7cd5c2",
   "metadata": {},
   "source": [
    "Lets run a couple easy statistical tests for all fit indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_amplitudes = results.get_significant_amplitudes()\n",
    "significant_phases = results.get_significant_phases()\n",
    "columns = list(sig_amplitudes) + list(significant_phases)\n",
    "\n",
    "if results.bootstrap_df is None: # assure type hinter that bootstrap df exists\n",
    "    raise ValueError(\"Bootstrap dataframe is not available in results.\")\n",
    "\n",
    "stats.normality_test(results.fit_df, results.bootstrap_df, columns, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5837f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.bootstrap_df is None: # assure type hinter that bootstrap df exists\n",
    "    raise ValueError(\"Bootstrap dataframe is not available in results.\")\n",
    "stats.bias_test(results.fit_df, results.bootstrap_df, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf57e0",
   "metadata": {},
   "source": [
    "### Broad Exploration of Problematic Region\n",
    "It's clear we're having issues in the 1.0-1.3 GeV mass region. Let's explore that on a wider scale to hopefully hone in on what could be the problem. First we'll look for any consistently strong correlations in this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results.bootstrap_df is None: # assure type hinter that bootstrap df exists\n",
    "    raise ValueError(\"Bootstrap dataframe is not available in results.\")\n",
    "\n",
    "fit_indices = list(np.arange(0, 31, dtype=int))\n",
    "\n",
    "all_phases = results.phase_differences\n",
    "significant_phases = results.get_significant_phases(fit_indices=fit_indices)\n",
    "drop_phases = all_phases - significant_phases\n",
    "columns_to_drop = list(drop_phases)\n",
    "columns_to_drop.extend([\"m\", \"p\", \"1p\", \"1m\", \"m1p\", \"p1p\"])\n",
    "\n",
    "stats.report_correlations(\n",
    "    results.bootstrap_df, \n",
    "    fit_indices=fit_indices, \n",
    "    report_average=True, \n",
    "    drop_columns=columns_to_drop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a jp style plot of just the truth JP values, to replace in analysis note"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
