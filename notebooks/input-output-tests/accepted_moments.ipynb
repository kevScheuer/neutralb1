{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import neutralb1.utils\n",
    "\n",
    "WORKSPACE_DIR = neutralb1.utils.get_workspace_dir()\n",
    "\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=WORKSPACE_DIR).decode('utf-8').strip()\n",
    "print(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512adaa",
   "metadata": {},
   "source": [
    "**Repository Version** \n",
    "\n",
    "This notebook was run at commit:\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32fe62",
   "metadata": {},
   "source": [
    "# Acceptance-Correcting Projected Moments\n",
    "When partial wave fits are performed to data that includes detector acceptance effects, we typically perform an \"acceptance correction\" to remove those effects so that we obtain the *true physics* of the decay. If we want to project out moments from partial wave results, these partial waves must be acceptance corrected, otherwise the moments will be measured quantities that aren't of particular interest to us. In this study we'll verify that we are projecting and acceptance correcting properly by comparing moment values obtained from fits to **thrown** Monte Carlo (no detector acceptance) vs **accepted** Monte Carlo, were we've applied detector acceptance and other cuts to the thrown data.\n",
    "\n",
    "By performing partial wave fits in both datasets, we can check whether the acceptance-corrected projected moments of the accepted dataset match the projected moments of the thrown dataset. We also have access to the fitted moments in the thrown case, which can provide a further check that the projection is working well. Unfortunately, the fitted moments currently have no method to be\n",
    "acceptance-corrected, and so we can not fit moments to the accepted dataset.\n",
    "\n",
    "This notebook follows naturally from the previous [moment verification study](./verify_moment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90fc1c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91478f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load common libraries\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import scipy.stats\n",
    "\n",
    "# load neutralb1 libraries\n",
    "import neutralb1.utils as utils\n",
    "from neutralb1.analysis.result import ResultManager\n",
    "\n",
    "utils.load_environment()\n",
    "\n",
    "# load in useful directories as constants\n",
    "CWD = pathlib.Path.cwd()\n",
    "STUDY_DIR = f\"{WORKSPACE_DIR}/studies/input-output-tests/proj-acc-correct\"\n",
    "\n",
    "# set env variables for shell cells\n",
    "os.environ[\"WORKSPACE_DIR\"] = WORKSPACE_DIR\n",
    "os.environ['STUDY_DIR'] = STUDY_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf53b",
   "metadata": {},
   "source": [
    "Lets print out what parameters we've submitted the fit with. These are the same for thrown and accepted MC, except that `data_option` is changed to `'_mc'`. These fits are then run with `uv run submit submission.YAML`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ac921",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat $STUDY_DIR/submission.YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ae9f4",
   "metadata": {},
   "source": [
    "We then transfer only the necessary results of our fits to our study directory. First the thrown directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d76aa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /lustre24/expphy/volatile/halld/home/kscheuer/ampToolsFits/omegapi/allPeriods/PARA_0/ver03.1_mcthrown/ver03/1m_1p_iso/recoil_pi_mass_0.0/t_0.10-0.20/mass_1.200-1.220/\n",
    "cp best.csv \"$STUDY_DIR/csv/thrown.csv\"\n",
    "cp data.csv \"$STUDY_DIR/csv/thrown_data.csv\"\n",
    "cp best_projected_moments.csv \"$STUDY_DIR/csv/thrown_projected_moments.csv\"\n",
    "cp distributions/angles.pdf \"$STUDY_DIR/thrown_angles.pdf\"\n",
    "\n",
    "cp truth/best.csv \"$STUDY_DIR/csv/thrown_truth.csv\"\n",
    "cp truth/best_projected_moments.csv \"$STUDY_DIR/csv/thrown_truth_projected_moments.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca76fb",
   "metadata": {},
   "source": [
    "And now for the accepted MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928307e3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /lustre24/expphy/volatile/halld/home/kscheuer/ampToolsFits/omegapi/allPeriods/PARA_0/ver03.1_mc/ver03/1m_1p_iso/recoil_pi_mass_0.0/t_0.10-0.20/mass_1.200-1.220/\n",
    "cp best.csv \"$STUDY_DIR/csv/acceptance.csv\"\n",
    "cp best_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected.csv\"\n",
    "cp data.csv \"$STUDY_DIR/csv/acceptance_data.csv\"\n",
    "cp bootstrap/bootstrap.csv \"$STUDY_DIR/csv/acceptance_bootstrap.csv\"\n",
    "cp bootstrap/bootstrap_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected_bootstrap.csv\"\n",
    "cp bootstrap/bootstrap_projected_moments.csv \"$STUDY_DIR/csv/acceptance_bootstrap_projected_moments.csv\"\n",
    "\n",
    "cp best_projected_moments.csv \"$STUDY_DIR/csv/acceptance_projected_moments.csv\"\n",
    "cp distributions/angles.pdf \"$STUDY_DIR/acceptance_angles.pdf\"\n",
    "\n",
    "\n",
    "cp truth/best.csv \"$STUDY_DIR/csv/acceptance_truth.csv\"\n",
    "cp truth/best_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected_truth.csv\"\n",
    "cp truth/best_projected_moments.csv \"$STUDY_DIR/csv/acceptance_truth_projected_moments.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69514961",
   "metadata": {},
   "source": [
    "Lets now load in our data files into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown.csv\")\n",
    "thrown_data_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_data.csv\")\n",
    "thrown_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_projected_moments.csv\")\n",
    "\n",
    "truth_thrown_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_truth.csv\")\n",
    "truth_thrown_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_truth_projected_moments.csv\")\n",
    "\n",
    "\n",
    "acc_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance.csv\")\n",
    "acc_corrected_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected.csv\")\n",
    "acc_data_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_data.csv\")\n",
    "acc_bootstrap_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_bootstrap.csv\")\n",
    "acc_corrected_bootstrap_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected_bootstrap.csv\")\n",
    "acc_bootstrap_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_bootstrap_projected_moments.csv\")\n",
    "acc_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_projected_moments.csv\")\n",
    "\n",
    "truth_acc_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_truth.csv\")\n",
    "truth_acc_corrected_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected_truth.csv\")\n",
    "truth_acc_corrected_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_truth_projected_moments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf664ef",
   "metadata": {},
   "source": [
    "It'll be much easier to manage the thrown and accepted signal MC results with the result manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f543e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_result = ResultManager(\n",
    "    fit_df = thrown_waves_df,\n",
    "    data_df = thrown_data_df,\n",
    "    proj_moments_df=thrown_moments_df,    \n",
    "    truth_df = truth_thrown_waves_df,\n",
    "    truth_proj_moments_df=truth_thrown_moments_df,\n",
    ")\n",
    "\n",
    "# projected moments are always acceptance corrected currently, so they're not included in this result\n",
    "acc_result = ResultManager(\n",
    "    fit_df = acc_waves_df,\n",
    "    data_df = acc_data_df,\n",
    "    bootstrap_df = acc_bootstrap_df,\n",
    "    truth_df = truth_acc_waves_df,\n",
    ")\n",
    "\n",
    "acc_corrected_result = ResultManager(\n",
    "    fit_df = acc_corrected_waves_df,\n",
    "    data_df = acc_data_df,\n",
    "    bootstrap_df = acc_bootstrap_df,\n",
    "    proj_moments_df = acc_moments_df,\n",
    "    bootstrap_proj_moments_df = acc_bootstrap_moments_df,\n",
    "    truth_df = truth_acc_corrected_waves_df,\n",
    "    truth_proj_moments_df = truth_acc_corrected_moments_df,\n",
    ")\n",
    "\n",
    "thrown_result.preprocess()\n",
    "acc_result.preprocess()\n",
    "acc_corrected_result.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994df2e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fbc6d",
   "metadata": {},
   "source": [
    "### Fits to Distributions\n",
    "Let's first make sure the angular distributions look alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_pdf(f\"{STUDY_DIR}/thrown_angles.pdf\", page=0, resolution=150)\n",
    "utils.display_pdf(f\"{STUDY_DIR}/acceptance_angles.pdf\", page=0, resolution=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424d7dd",
   "metadata": {},
   "source": [
    "### Checking the Acceptance Correction va Truth Fits\n",
    "We can see how the acceptance correction effects our results by comparing the truth fits in the thrown and accepted cases. A \"truth\" fit is one where the production coefficients are fixed to their generated values, and only a common scale factor is allowed to float so that the intensity can be adjusted to the number of events. This is because the generated production coefficients are sensitive to the intensity they were fit with, and so generated or accepted MC will have a different number of events. In either thrown or accepted cases, the production coefficients will be the same, just with a modified scale factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e692fb",
   "metadata": {},
   "source": [
    "#### Partial Wave Fits\n",
    "Let's first see how the waves were effected by comparing the ratio $A_{\\text{acc-corrected}} / A_{\\text{thrown}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = utils.get_coherent_sums(acc_corrected_result.truth_df)[\"eJPmL\"]\n",
    "\n",
    "ratios = []\n",
    "for amp in amplitudes:\n",
    "    acc_value = acc_corrected_result.truth_df[amp].values[0]\n",
    "    thrown_value = thrown_result.truth_df[amp].values[0]    \n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.bar(amplitudes, ratios)\n",
    "ax.set_ylabel(r\"$A_{\\text{acc-corrected}} ~/~ A_{\\text{thrown}}$\")\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Amplitudes\")\n",
    "ax.set_xticks(range(len(amplitudes)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes], rotation=45)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b72ddd",
   "metadata": {},
   "source": [
    "There seems to be a common factor missing. We can notice that the number of events that we get when acceptance correcting does not match the number of events that we generated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Truth Thrown Generated Events: \\t\\t\\t{thrown_result.fit_df['generated_events'].values[0]}\")\n",
    "print(f\"Truth Acceptance Corrected Generated Events: \\t{acc_corrected_result.fit_df['generated_events'].values[0]}\")\n",
    "\n",
    "percent_diff = 100 * (acc_corrected_result.fit_df['generated_events'].values[0] - thrown_result.fit_df['generated_events'].values[0]) / thrown_result.fit_df['generated_events'].values[0]\n",
    "print(f\"Percent Difference in Generated Events: \\t{percent_diff:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565f10d",
   "metadata": {},
   "source": [
    "If we divide out this value for each case, we can check if the ratios now deviate from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c97329",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = utils.get_coherent_sums(acc_corrected_result.truth_df)[\"eJPmL\"]\n",
    "\n",
    "ratios = []\n",
    "for amp in amplitudes:\n",
    "    acc_value = acc_corrected_result.truth_df[amp].values[0] / acc_corrected_result.truth_df[\"generated_events\"].values[0]\n",
    "    thrown_value = thrown_result.truth_df[amp].values[0] / thrown_result.truth_df[\"generated_events\"].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    ratios.append(ratio)\n",
    "\n",
    "if not np.allclose(ratios, 1.0, atol=1e-2):\n",
    "    raise ValueError(\"Warning: Acceptance correction may not be working well, ratios deviate from 1 by more than 1%\")    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.bar(amplitudes, ratios)\n",
    "# \\text{Intensity_{\\text{acc-corrected}}}\n",
    "ax.set_ylabel(r\"$\\dfrac{\\left(\\frac{A}{Intensity}\\right)_{\\text{acc-corrected}}}{\\left(\\frac{A}{Intensity}\\right)_{\\text{thrown}}} $\")\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Amplitude Fit Fractions\")\n",
    "ax.set_xticks(range(len(amplitudes)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes], rotation=45)\n",
    "ax.set_ylim(0.8, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae05e42",
   "metadata": {},
   "source": [
    "Lastly, we can check the phase differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f156b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = list(utils.get_phase_differences(thrown_result.truth_df))\n",
    "\n",
    "ratios = []\n",
    "for pd in pds:\n",
    "    acc_value = acc_corrected_result.truth_df[pd].values[0]\n",
    "    thrown_value = thrown_result.truth_df[pd].values[0]    \n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan    \n",
    "    ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "ax.bar(pds, ratios)\n",
    "ax.set_ylabel(r\"$A_{\\text{acc-corrected}} ~/~ A_{\\text{thrown}}$\")\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Amplitudes\")\n",
    "ax.set_xticks(range(len(pds)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(pd) for pd in pds], rotation=45, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylim(0.85, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb304d",
   "metadata": {},
   "source": [
    "There appear to be two problematic phase differences, but we can see below that their values are extremely small. Since these are truth fits, they include Breit-Wigners which modulate the phase difference values. We corrected for this in the preprocess method of our ResultManager class earlier, but for small phase differences it likely introduces some error thats unaccounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pds = [\"p1ppD_p1m0P\", \"m1pmS_m1m0P\"]\n",
    "for pd in small_pds:\n",
    "    acc_value = acc_corrected_result.truth_df[pd].values[0]\n",
    "    thrown_value = thrown_result.truth_df[pd].values[0]    \n",
    "    print(f\"{pd}: acc={acc_value:.6f}, thrown={thrown_value:.6f}, ratio={acc_value/thrown_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed8f8c",
   "metadata": {},
   "source": [
    "#### Projected Moments\n",
    "Since the amplitudes are fixed, we should expect to find the same behavior in the projected moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310aa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_columns = [col for col in thrown_result.truth_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "\n",
    "truth_moment_ratios = []\n",
    "for m in moment_columns:\n",
    "    acc_value = acc_corrected_result.truth_proj_moments_df[m].values[0]\n",
    "    thrown_value = thrown_result.truth_proj_moments_df[m].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    truth_moment_ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(moment_columns, truth_moment_ratios)\n",
    "ax.set_ylabel(r\"$H_{\\text{acc-corrected}} ~/~ H_{\\text{thrown}}$\")\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Projected Moments\")\n",
    "ax.set_xticks(range(len(moment_columns)))\n",
    "ax.set_xticklabels(moment_columns, rotation=90)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620f40b",
   "metadata": {},
   "source": [
    "Now perform the same division by the relative number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_moment_ratios = []\n",
    "for m in moment_columns:\n",
    "    acc_value = acc_corrected_result.truth_proj_moments_df[m].values[0] / acc_corrected_result.truth_df[\"generated_events\"].values[0]\n",
    "    thrown_value = thrown_result.truth_proj_moments_df[m].values[0] / thrown_result.truth_df[\"generated_events\"].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    truth_moment_ratios.append(ratio)\n",
    "\n",
    "if not np.allclose(truth_moment_ratios, 1.0, atol=1e-2):\n",
    "    raise ValueError(\"Warning: Acceptance correction may not be working well, ratios deviate from 1 by more than 1%\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(moment_columns, truth_moment_ratios)\n",
    "ax.set_ylabel(r\"$\\dfrac{\\left(\\frac{H}{Intensity}\\right)_{\\text{acc-corrected}}}{\\left(\\frac{H}{Intensity}\\right)_{\\text{thrown}}} $\", fontsize=18)\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Projected Moment Fit Fractions\")\n",
    "ax.set_xticks(range(len(moment_columns)))\n",
    "ax.set_xticklabels(moment_columns, rotation=90)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d02f6",
   "metadata": {},
   "source": [
    "### Evaluating the Fit Result to the Accepted Monte Carlo\n",
    "With acceptable acceptance-correction from the previous section, we can turn our attention to the fit results in the accepted Monte Carlo. Here we have performed 100 randomized fit results, in which we will only look at the fit result with the best likelihood out of those 100. This \"best fit\" was used to seed 300 bootstrap fits so that we can obtain more reasonable errors on the partial wave results. The projected moments currently have no method for error propagation from the PWA results, so the bootstrap also provides us with projected moment errors we would otherwise lack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39b0e5",
   "metadata": {},
   "source": [
    "#### Accepted Partial Wave Result\n",
    "To understand how the result of our partial wave fit performed, we can compare it to the truth information. We'll do this first for the acceptance-included Monte Carlo, just to avoid any possible issues in the acceptance correction. We'll do the comparison by calculating the weighted residuals\n",
    "$$\n",
    "\\frac{A_{\\text{acc}} - A_{\\text{truth-acc}}}{\\sigma_{A,\\text{acc}}}\n",
    "$$\n",
    "Lets first check that the bootstrap uncertainties are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = utils.get_coherent_sums(acc_result.fit_df)[\"eJPmL\"]\n",
    "\n",
    "relative_uncertainties = []\n",
    "fit_fractions = []\n",
    "intensity = acc_result.fit_df.loc[0, \"generated_events\"]\n",
    "for amp in amplitudes:\n",
    "    value = acc_result.fit_df.loc[0, amp]\n",
    "    err = acc_result.bootstrap_df[f\"{amp}\"].std()\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan\n",
    "    relative_uncertainties.append(rel_unc)\n",
    "    fit_frac = value / intensity if intensity != 0 else np.nan\n",
    "    fit_fractions.append(fit_frac)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14, 5), sharex=True)\n",
    "\n",
    "axs[0].bar(amplitudes, relative_uncertainties)\n",
    "axs[0].set_ylabel(r\"$\\sigma_{|A|^2} ~/~|A|^2$\")\n",
    "axs[0].set_title(\"Relative Uncertainty for Each Amplitude\")\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axs[1].bar(amplitudes, fit_fractions, yerr=[\n",
    "    acc_result.bootstrap_df[amp].std() / intensity if intensity != 0 else 0 for amp in amplitudes\n",
    "])\n",
    "axs[1].set_xticks(range(len(amplitudes)))\n",
    "axs[1].set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes])\n",
    "axs[1].set_ylabel(r\"$|A|^2 /$ Intensity\")\n",
    "axs[1].set_title(\"Fit Fraction for Each Amplitude\")\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative uncertainties for phase differences using bootstrap\n",
    "phase_diffs = list(utils.get_phase_differences(acc_result.fit_df))\n",
    "relative_uncertainties_pd = []\n",
    "avg_fit_fractions = []\n",
    "\n",
    "intensity = acc_result.fit_df.loc[0, \"generated_events\"]\n",
    "for pd in phase_diffs:\n",
    "    val = acc_result.fit_df.loc[0, pd]    \n",
    "    val_err = np.rad2deg(scipy.stats.circstd(np.deg2rad(acc_result.bootstrap_df[pd]), low=-np.pi, high=np.pi))\n",
    "    rel_unc = abs(val_err / val) if val != 0 else np.nan\n",
    "    relative_uncertainties_pd.append(rel_unc)\n",
    "\n",
    "    # Get the two amplitudes involved in the phase difference\n",
    "    amp1, amp2 = pd.split('_')\n",
    "    fit_frac1 = acc_result.fit_df.loc[0, amp1] / intensity if intensity != 0 else np.nan\n",
    "    fit_frac2 = acc_result.fit_df.loc[0, amp2] / intensity if intensity != 0 else np.nan\n",
    "    avg_fit_fractions.append(0.5 * (abs(fit_frac1) + abs(fit_frac2)))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 8), sharex=True)\n",
    "\n",
    "axs[0].bar(phase_diffs, relative_uncertainties_pd)\n",
    "axs[0].set_ylabel(r\"$\\sigma_{\\eta_{A_1, A_2}} / \\eta_{A_1, A_2}$\", fontsize=20)\n",
    "axs[0].set_title(\"Relative Uncertainty for Each Phase Difference (Accepted MC)\")\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "axs[0].axhline(1, color='r', linestyle='-', linewidth=1)\n",
    "\n",
    "axs[1].bar(phase_diffs, avg_fit_fractions)\n",
    "axs[1].set_ylabel(r\"$\\frac{|A_1|^2 + |A_2|^2}{2 \\times \\text{Intensity}}$\", fontsize=20)\n",
    "axs[1].set_title(\"Average Fit Fraction of Amplitudes in Each Phase Difference\")\n",
    "axs[1].set_xticks(range(len(phase_diffs)))\n",
    "axs[1].set_xticklabels([utils.convert_amp_name(pd) for pd in phase_diffs], rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5380c7",
   "metadata": {},
   "source": [
    "Now we can calculate the weighted residuals for all amplitudes and phase differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted residuals for each amplitude\n",
    "weighted_residuals = []\n",
    "\n",
    "for amp in amplitudes:     \n",
    "    acc_val = acc_result.fit_df.loc[0, amp] \n",
    "    acc_err = acc_result.bootstrap_df[f\"{amp}\"].std()\n",
    "\n",
    "    true_val = acc_result.truth_df.loc[0, amp]\n",
    "\n",
    "    if acc_err != 0:\n",
    "        residual = (acc_val - true_val) / acc_err\n",
    "    else:\n",
    "        residual = np.nan\n",
    "    weighted_residuals.append(residual)\n",
    "\n",
    "for pd in phase_diffs:\n",
    "    acc_val = acc_result.fit_df.loc[0, pd]\n",
    "    acc_err = np.rad2deg(scipy.stats.circstd(np.deg2rad(acc_result.bootstrap_df[pd]), low=-np.pi, high=np.pi))    \n",
    "    true_val = acc_result.truth_df.loc[0, pd]\n",
    "    # Use difference of absolute values due to phase ambiguity\n",
    "    if acc_err != 0:\n",
    "        residual = (np.abs(acc_val) - np.abs(true_val)) / acc_err\n",
    "    else:\n",
    "        residual = np.nan\n",
    "    weighted_residuals.append(residual)\n",
    "\n",
    "reduced_chi2 = np.nansum(np.array(weighted_residuals)**2) / (len(amplitudes) + len(phase_diffs) - 1)\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.bar(amplitudes + phase_diffs, weighted_residuals)\n",
    "plt.ylabel(r\"$\\frac{A_{\\text{acc}} - A_{\\text{true}}}{\\sigma_{A_{\\text{acc}}}}$\", fontsize=20)\n",
    "plt.xticks(range(len(amplitudes + phase_diffs)), [utils.convert_amp_name(label) for label in amplitudes + phase_diffs], rotation=45)\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.annotate(rf\"$\\chi^2 ~/~\\text{{dof}} = {reduced_chi2:.2f}$\", xy=(1, 1), xycoords='axes fraction',\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            fontsize=12)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451c4fb",
   "metadata": {},
   "source": [
    "#### Acceptance-Corrected Partial Wave Result\n",
    "Before taking a look at the moments, we can check that our acceptance correction worked well for the partial waves first. We'll want to calculate the weighted residuals, or\n",
    "$$\n",
    "\\frac{A_{\\text{acc-corrected}}' - A_{\\text{truth-thrown}}'}{\\sigma_{A,\\text{acc-corrected}}'}\n",
    "$$\n",
    "where the prime indicates values normalized by the relative number of generated events:\n",
    "$$\n",
    "A_{\\text{acc-corrected}}' = \\frac{A_{\\text{acc-corrected}}}{\\text{generated events}}\n",
    "\\,.\n",
    "$$\n",
    "But first we need to ensure the bootstrap uncertainties are reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = utils.get_coherent_sums(acc_corrected_result.fit_df)[\"eJPmL\"]\n",
    "\n",
    "relative_uncertainties = []\n",
    "fit_fractions = []\n",
    "intensity = acc_corrected_result.fit_df.loc[0, \"generated_events\"]\n",
    "for amp in amplitudes:\n",
    "    value = acc_corrected_result.fit_df.loc[0, amp]\n",
    "    err = acc_corrected_result.bootstrap_df[f\"{amp}\"].std()\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan\n",
    "    relative_uncertainties.append(rel_unc)\n",
    "    fit_frac = value / intensity if intensity != 0 else np.nan\n",
    "    fit_fractions.append(fit_frac)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14, 5), sharex=True)\n",
    "\n",
    "axs[0].bar(amplitudes, relative_uncertainties)\n",
    "axs[0].set_ylabel(r\"$\\sigma_{|A|^2} ~/~|A|^2$\")\n",
    "axs[0].set_title(\"Relative Uncertainty for Each Amplitude (Acceptance Corrected)\")\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axs[1].bar(amplitudes, fit_fractions, yerr=[\n",
    "    acc_corrected_result.bootstrap_df[amp].std() / intensity if intensity != 0 else 0 for amp in amplitudes\n",
    "])\n",
    "axs[1].set_xticks(range(len(amplitudes)))\n",
    "axs[1].set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes])\n",
    "axs[1].set_ylabel(r\"$|A|^2 /$ Intensity\")\n",
    "axs[1].set_title(\"Fit Fraction for Each Amplitude (Acceptance Corrected)\")\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find relative uncertainties for the phase differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2f1dc",
   "metadata": {},
   "source": [
    "As expected, we have large uncertainties for the amplitudes with very small contributions to the intensity, which is okay. Now we can calculate the weighted residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718af022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted residuals for each amplitude\n",
    "weighted_residuals = []\n",
    "acc_intensity = acc_corrected_result.fit_df.loc[0, \"generated_events\"]\n",
    "thrown_intensity = thrown_result.truth_df.loc[0, \"generated_events\"]\n",
    "\n",
    "for amp in amplitudes:     \n",
    "    acc_val = acc_corrected_result.fit_df.loc[0, amp] / acc_intensity\n",
    "    acc_err = acc_corrected_result.bootstrap_df[f\"{amp}\"].std() / acc_intensity\n",
    "\n",
    "    thrown_val = thrown_result.truth_df.loc[0, amp] / thrown_intensity\n",
    "\n",
    "    if acc_err != 0:\n",
    "        residual = (acc_val - thrown_val) / acc_err\n",
    "    else:\n",
    "        residual = np.nan\n",
    "    weighted_residuals.append(residual)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.bar(amplitudes, weighted_residuals)\n",
    "plt.ylabel(r\"$\\frac{A'_{\\text{acc}} - A'_{\\text{thrown}}}{\\sigma'_{A'_{\\text{acc}}}}$\", fontsize=20)\n",
    "plt.xticks(range(len(amplitudes)), [utils.convert_amp_name(amp) for amp in amplitudes], rotation=45)\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: take a look at non-acceptance corrected case to see if those largest amplitudes are also under-estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095461ef",
   "metadata": {},
   "source": [
    "And do the same for the phase differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: weighted residuals of phase differences. Need to calculate absolute difference due to ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0df1f",
   "metadata": {},
   "source": [
    "#### Projected Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [col for col in thrown_result.truth_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "\n",
    "relative_uncertainties = []\n",
    "fit_fractions = []\n",
    "H0_0000 = acc_corrected_result.bootstrap_proj_moments_df.loc[0, \"H0_0000\"]\n",
    "for mom in moments:\n",
    "    value = acc_corrected_result.proj_moments_df.loc[0, mom]\n",
    "    err = acc_corrected_result.bootstrap_proj_moments_df[mom].std()\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan\n",
    "    relative_uncertainties.append(rel_unc)\n",
    "    fit_frac = value / H0_0000 if H0_0000 != 0 else np.nan\n",
    "    fit_fractions.append(abs(fit_frac))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14, 5), sharex=True)\n",
    "\n",
    "axs[0].bar(moments, relative_uncertainties)\n",
    "axs[0].set_ylabel(r\"$\\sigma_{H} ~/~ H$\")\n",
    "axs[0].set_title(\"Relative Uncertainty for Each Moment (Acceptance Corrected)\")\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axs[1].bar(moments, fit_fractions, yerr=[\n",
    "    acc_corrected_result.bootstrap_proj_moments_df[mom].std() / H0_0000 if H0_0000 != 0 else 0 for mom in moments\n",
    "])\n",
    "axs[1].set_xticks(range(len(moments)))\n",
    "axs[1].set_ylabel(r\"$|H ~/~ H0\\_0000|$ \")\n",
    "axs[1].set_title(\"Normalized Moments (Acceptance Corrected)\")\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd94699",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_residuals_moments = []\n",
    "acc_intensity = acc_corrected_result.fit_df.loc[0, \"generated_events\"]\n",
    "thrown_intensity = thrown_result.truth_df.loc[0, \"generated_events\"]\n",
    "\n",
    "for mom in moments:\n",
    "    acc_val = acc_corrected_result.proj_moments_df.loc[0, mom] / acc_intensity\n",
    "    acc_err = acc_corrected_result.bootstrap_proj_moments_df[mom].std() / acc_intensity\n",
    "    thrown_val = thrown_result.truth_proj_moments_df.loc[0, mom] / thrown_intensity\n",
    "\n",
    "    if acc_err != 0:\n",
    "        residual = (acc_val - thrown_val) / acc_err #TODO: make the relative difference another plot\n",
    "    else:\n",
    "        residual = np.nan\n",
    "    weighted_residuals_moments.append(residual)\n",
    "\n",
    "reduced_chi2 = np.nansum(np.array(weighted_residuals_moments)**2) / (len(moments) - 1)\n",
    "print(f\"Reduced Chi^2 for Moments: {reduced_chi2:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.bar(moments, weighted_residuals_moments)\n",
    "plt.ylabel(r\"$\\frac{H'_{\\text{acc}} - H'_{\\text{thrown}}}{\\sigma'_{H'_{\\text{acc}}}}$\", fontsize=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted residuals between thrown_fitted_moments_df and filtered_thrown_moments_df\n",
    "residuals_truth_vs_fit_moments = []\n",
    "for mom in moments:\n",
    "    corrected_val = filtered_acc_corrected_moments_df.loc[0, mom]\n",
    "    projected_val = filtered_truth_thrown_moments_df.loc[0, mom]\n",
    "    # residuals_truth_vs_fit_moments.append((projected_val - corrected_val) / projected_val)\n",
    "    residuals_truth_vs_fit_moments.append((projected_val / corrected_val))\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.bar(moments, residuals_truth_vs_fit_moments)\n",
    "plt.ylabel(\"x\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.axhline(1, color='k', linestyle='--', linewidth=1)\n",
    "plt.ylim(0,3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a8de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
