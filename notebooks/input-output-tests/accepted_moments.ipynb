{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import neutralb1.utils\n",
    "\n",
    "WORKSPACE_DIR = neutralb1.utils.get_workspace_dir()\n",
    "\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=WORKSPACE_DIR).decode('utf-8').strip()\n",
    "print(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512adaa",
   "metadata": {},
   "source": [
    "**Repository Version** \n",
    "\n",
    "This notebook was run at commit:\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32fe62",
   "metadata": {},
   "source": [
    "# Acceptance-Correcting Projected Moments\n",
    "When partial wave fits are performed to data that includes detector acceptance effects, we typically perform an \"acceptance correction\" to remove those effects so that we obtain the *true physics* of the decay. If we want to project out moments from partial wave results, these partial waves must be acceptance corrected, otherwise the moments will be measured quantities that aren't of particular interest to us. In this study we'll verify that we are projecting and acceptance correcting properly by comparing moment values obtained from fits to **thrown** Monte Carlo (no detector acceptance) vs **accepted** Monte Carlo, were we've applied detector acceptance and other cuts to the thrown data.\n",
    "\n",
    "By performing partial wave fits in both datasets, we can check whether the acceptance-corrected projected moments of the accepted dataset match the projected moments of the thrown dataset. We also have access to the fitted moments in the thrown case, which can provide a further check that the projection is working well. Unfortunately, the fitted moments currently have no method to be\n",
    "acceptance-corrected, and so we can not fit moments to the accepted dataset.\n",
    "\n",
    "This notebook follows naturally from the previous [moment verification study](./verify_moment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90fc1c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91478f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load common libraries\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import scipy.stats\n",
    "\n",
    "# load neutralb1 libraries\n",
    "import neutralb1.utils as utils\n",
    "from neutralb1.analysis.result import ResultManager\n",
    "\n",
    "utils.load_environment()\n",
    "\n",
    "# load in useful directories as constants\n",
    "CWD = pathlib.Path.cwd()\n",
    "STUDY_DIR = f\"{WORKSPACE_DIR}/studies/input-output-tests/proj-acc-correct\"\n",
    "\n",
    "# set env variables for shell cells\n",
    "os.environ[\"WORKSPACE_DIR\"] = WORKSPACE_DIR\n",
    "os.environ['STUDY_DIR'] = STUDY_DIR\n",
    "\n",
    "# TODO: load in matploblib style then adjust subsequent plot looks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf53b",
   "metadata": {},
   "source": [
    "Lets print out what parameters we've submitted the fit with. These are the same for thrown and accepted MC, except that `data_option` is changed to `'_mc'`. These fits are then run with `uv run submit submission.YAML`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ac921",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat $STUDY_DIR/submission.YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ae9f4",
   "metadata": {},
   "source": [
    "We then transfer only the necessary results of our fits to our study directory. First the thrown directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d76aa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /lustre24/expphy/volatile/halld/home/kscheuer/ampToolsFits/omegapi/allPeriods/PARA_0/ver03.1_mcthrown/ver03/1m_1p_iso/recoil_pi_mass_0.0/t_0.10-0.20/mass_1.200-1.220/\n",
    "cp best.csv \"$STUDY_DIR/csv/thrown.csv\"\n",
    "cp data.csv \"$STUDY_DIR/csv/thrown_data.csv\"\n",
    "cp best_projected_moments.csv \"$STUDY_DIR/csv/thrown_projected_moments.csv\"\n",
    "cp distributions/angles.pdf \"$STUDY_DIR/thrown_angles.pdf\"\n",
    "\n",
    "cp truth/best.csv \"$STUDY_DIR/csv/thrown_truth.csv\"\n",
    "cp truth/best_projected_moments.csv \"$STUDY_DIR/csv/thrown_truth_projected_moments.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca76fb",
   "metadata": {},
   "source": [
    "And now for the accepted MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928307e3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /lustre24/expphy/volatile/halld/home/kscheuer/ampToolsFits/omegapi/allPeriods/PARA_0/ver03.1_mc/ver03/1m_1p_iso/recoil_pi_mass_0.0/t_0.10-0.20/mass_1.200-1.220/\n",
    "cp best.csv \"$STUDY_DIR/csv/acceptance.csv\"\n",
    "cp best_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected.csv\"\n",
    "cp data.csv \"$STUDY_DIR/csv/acceptance_data.csv\"\n",
    "cp rand/rand_acceptance_corrected.csv \"$STUDY_DIR/csv/rand_acceptance_corrected.csv\"\n",
    "cp rand/rand_projected_moments.csv \"$STUDY_DIR/csv/acceptance_rand_projected_moments.csv\"\n",
    "cp bootstrap/bootstrap.csv \"$STUDY_DIR/csv/acceptance_bootstrap.csv\"\n",
    "cp bootstrap/bootstrap_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected_bootstrap.csv\"\n",
    "cp bootstrap/bootstrap_projected_moments.csv \"$STUDY_DIR/csv/acceptance_bootstrap_projected_moments.csv\"\n",
    "\n",
    "cp best_projected_moments.csv \"$STUDY_DIR/csv/acceptance_projected_moments.csv\"\n",
    "cp distributions/angles.pdf \"$STUDY_DIR/acceptance_angles.pdf\"\n",
    "\n",
    "\n",
    "cp truth/best.csv \"$STUDY_DIR/csv/acceptance_truth.csv\"\n",
    "cp truth/best_corrected.csv \"$STUDY_DIR/csv/acceptance_corrected_truth.csv\"\n",
    "cp truth/best_projected_moments.csv \"$STUDY_DIR/csv/acceptance_truth_projected_moments.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69514961",
   "metadata": {},
   "source": [
    "Lets now load in our data files into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown.csv\")\n",
    "thrown_data_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_data.csv\")\n",
    "thrown_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_projected_moments.csv\")\n",
    "\n",
    "truth_thrown_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_truth.csv\")\n",
    "truth_thrown_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/thrown_truth_projected_moments.csv\")\n",
    "\n",
    "\n",
    "acc_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance.csv\")\n",
    "acc_corrected_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected.csv\")\n",
    "acc_data_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_data.csv\")\n",
    "acc_corrected_rand_df = pd.read_csv(f\"{STUDY_DIR}/csv/rand_acceptance_corrected.csv\")\n",
    "acc_rand_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_rand_projected_moments.csv\")\n",
    "acc_bootstrap_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_bootstrap.csv\")\n",
    "acc_corrected_bootstrap_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected_bootstrap.csv\")\n",
    "acc_bootstrap_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_bootstrap_projected_moments.csv\")\n",
    "acc_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_projected_moments.csv\")\n",
    "\n",
    "truth_acc_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_truth.csv\")\n",
    "truth_acc_corrected_waves_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_corrected_truth.csv\")\n",
    "truth_acc_corrected_moments_df = pd.read_csv(f\"{STUDY_DIR}/csv/acceptance_truth_projected_moments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf664ef",
   "metadata": {},
   "source": [
    "It'll be much easier to manage the thrown and accepted signal MC results with the result manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f543e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_result = ResultManager(\n",
    "    fit_df = thrown_waves_df,\n",
    "    data_df = thrown_data_df,\n",
    "    proj_moments_df=thrown_moments_df,    \n",
    "    truth_df = truth_thrown_waves_df,\n",
    "    truth_proj_moments_df=truth_thrown_moments_df,\n",
    ")\n",
    "\n",
    "# projected moments are always acceptance corrected currently, so they're not included in this result\n",
    "acc_result = ResultManager(\n",
    "    fit_df = acc_waves_df,\n",
    "    data_df = acc_data_df,\n",
    "    bootstrap_df = acc_bootstrap_df,\n",
    "    truth_df = truth_acc_waves_df,\n",
    ")\n",
    "\n",
    "acc_corrected_result = ResultManager(\n",
    "    fit_df = acc_corrected_waves_df,\n",
    "    data_df = acc_data_df,\n",
    "    randomized_df = acc_corrected_rand_df,\n",
    "    randomized_proj_moments_df = acc_rand_moments_df,\n",
    "    bootstrap_df = acc_corrected_bootstrap_df,\n",
    "    proj_moments_df = acc_moments_df,\n",
    "    bootstrap_proj_moments_df = acc_bootstrap_moments_df,\n",
    "    truth_df = truth_acc_corrected_waves_df,\n",
    "    truth_proj_moments_df = truth_acc_corrected_moments_df,\n",
    ")\n",
    "\n",
    "thrown_result.preprocess()\n",
    "acc_result.preprocess()\n",
    "acc_corrected_result.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994df2e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fbc6d",
   "metadata": {},
   "source": [
    "### Fits to Distributions\n",
    "Let's first make sure the angular distributions look alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_pdf(f\"{STUDY_DIR}/thrown_angles.pdf\", page=0, resolution=150)\n",
    "utils.display_pdf(f\"{STUDY_DIR}/acceptance_angles.pdf\", page=0, resolution=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424d7dd",
   "metadata": {},
   "source": [
    "### Checking the Acceptance Correction via Truth Fits\n",
    "We can see how the acceptance correction effects our results by comparing the truth fits in the thrown and accepted cases. A \"truth\" fit is one where the production coefficients are fixed to their generated values, and only a common scale factor is allowed to float so that the intensity can be adjusted to the number of events. This is because the generated production coefficients are sensitive to the intensity they were fit with, and so generated or accepted MC will have a different number of events. In either thrown or accepted cases, the production coefficients will be the same, just with a modified scale factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e692fb",
   "metadata": {},
   "source": [
    "#### Partial Wave Fits\n",
    "Let's first see how the waves were effected by comparing the ratio $A_{\\text{acc-corrected}} / A_{\\text{thrown}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = utils.get_coherent_sums(acc_corrected_result.truth_df)[\"eJPmL\"]\n",
    "\n",
    "ratios = []\n",
    "for amp in amplitudes:\n",
    "    acc_value = acc_corrected_result.truth_df[amp].values[0]\n",
    "    thrown_value = thrown_result.truth_df[amp].values[0]    \n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.bar(amplitudes, ratios)\n",
    "ax.set_ylabel(r\"$A_{\\text{acc-corrected}} ~/~ A_{\\text{thrown}}$\", fontsize=18)\n",
    "ax.set_title(\"Truth Fits: Ratio of Acceptance Corrected to Thrown Amplitudes\")\n",
    "ax.set_xticks(range(len(amplitudes)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes], rotation=45)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b72ddd",
   "metadata": {},
   "source": [
    "There seems to be a common factor missing. We can notice that the number of events that we get when acceptance correcting does not match the number of events that we generated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Truth Thrown Generated Events: \\t\\t\\t{thrown_result.fit_df['generated_events'].values[0]}\")\n",
    "print(f\"Truth Acceptance Corrected Generated Events: \\t{acc_corrected_result.fit_df['generated_events'].values[0]}\")\n",
    "\n",
    "percent_diff = 100 * (acc_corrected_result.fit_df['generated_events'].values[0] - thrown_result.fit_df['generated_events'].values[0]) / thrown_result.fit_df['generated_events'].values[0]\n",
    "print(f\"Percent Difference in Generated Events: \\t{percent_diff:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565f10d",
   "metadata": {},
   "source": [
    "If we divide out this value for each case, we can check if the ratios now deviate from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c97329",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = utils.get_coherent_sums(acc_corrected_result.truth_df)[\"eJPmL\"]\n",
    "\n",
    "ratios = []\n",
    "for amp in amplitudes:\n",
    "    acc_value = acc_corrected_result.truth_df[amp].values[0] / acc_corrected_result.truth_df[\"generated_events\"].values[0]\n",
    "    thrown_value = thrown_result.truth_df[amp].values[0] / thrown_result.truth_df[\"generated_events\"].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    ratios.append(ratio)\n",
    "\n",
    "if not np.allclose(ratios, 1.0, atol=1e-2):\n",
    "    raise ValueError(\"Warning: Acceptance correction may not be working well, ratios deviate from 1 by more than 1%\")    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.bar(amplitudes, ratios)\n",
    "# \\text{Intensity_{\\text{acc-corrected}}}\n",
    "ax.set_ylabel(r\"$\\dfrac{\\left(\\frac{A}{Intensity}\\right)_{\\text{acc-corrected}}}{\\left(\\frac{A}{Intensity}\\right)_{\\text{thrown}}} $\", fontsize=18)\n",
    "ax.set_title(\"Truth Fits: Ratio of Acceptance Corrected to Thrown Amplitude Fit Fractions\")\n",
    "ax.set_xticks(range(len(amplitudes)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes], rotation=45)\n",
    "ax.set_ylim(0.8, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae05e42",
   "metadata": {},
   "source": [
    "Lastly, we can check the phase differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f156b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_diffs = list(utils.get_phase_differences(thrown_result.truth_df))\n",
    "\n",
    "ratios = []\n",
    "for phase_diff in phase_diffs:\n",
    "    acc_value = acc_corrected_result.truth_df[phase_diff].values[0]\n",
    "    thrown_value = thrown_result.truth_df[phase_diff].values[0]    \n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan    \n",
    "    ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 5))\n",
    "ax.bar(phase_diffs, ratios)\n",
    "ax.set_ylabel(r\"$\\eta_{\\text{acc-corrected}} ~/~ \\eta_{\\text{thrown}}$\", fontsize=18)\n",
    "ax.set_title(\"Truth Fits: Ratio of Acceptance Corrected to Thrown Phase Differences\")\n",
    "ax.set_xticks(range(len(phase_diffs)))\n",
    "ax.set_xticklabels([utils.convert_amp_name(phase_diff) for phase_diff in phase_diffs], rotation=45, ha='right', rotation_mode='anchor')\n",
    "ax.set_ylim(0.85, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb304d",
   "metadata": {},
   "source": [
    "There appear to be two problematic phase differences, but we can see below that their values are extremely small. Since these are truth fits, they include Breit-Wigners which modulate the phase difference values. We corrected for this in the preprocess method of our ResultManager class earlier, but for small phase differences it likely introduces some error thats unaccounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pds = [\"p1ppD_p1m0P\", \"m1pmS_m1m0P\"]\n",
    "for phase_diff in small_pds:\n",
    "    acc_value = acc_corrected_result.truth_df[phase_diff].values[0]\n",
    "    thrown_value = thrown_result.truth_df[phase_diff].values[0]    \n",
    "    print(f\"{phase_diff}: acc={acc_value:.6f}, thrown={thrown_value:.6f}, ratio={acc_value/thrown_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed8f8c",
   "metadata": {},
   "source": [
    "#### Projected Moments\n",
    "Since the amplitudes are fixed, we should expect to find the same behavior in the projected moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310aa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_columns = [col for col in thrown_result.truth_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "\n",
    "truth_moment_ratios = []\n",
    "for m in moment_columns:\n",
    "    acc_value = acc_corrected_result.truth_proj_moments_df[m].values[0]\n",
    "    thrown_value = thrown_result.truth_proj_moments_df[m].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    truth_moment_ratios.append(ratio)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(moment_columns, truth_moment_ratios)\n",
    "ax.set_ylabel(r\"$H_{\\text{acc-corrected}} ~/~ H_{\\text{thrown}}$\", fontsize=18)\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Projected Moments\")\n",
    "ax.set_xticks(range(len(moment_columns)))\n",
    "ax.set_xticklabels(moment_columns, rotation=90)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620f40b",
   "metadata": {},
   "source": [
    "Now perform the same division by the relative number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_moment_ratios = []\n",
    "for m in moment_columns:\n",
    "    acc_value = acc_corrected_result.truth_proj_moments_df[m].values[0] / acc_corrected_result.truth_df[\"generated_events\"].values[0]\n",
    "    thrown_value = thrown_result.truth_proj_moments_df[m].values[0] / thrown_result.truth_df[\"generated_events\"].values[0]\n",
    "    ratio = acc_value / thrown_value if thrown_value != 0 else np.nan\n",
    "    truth_moment_ratios.append(ratio)\n",
    "\n",
    "if not np.allclose(truth_moment_ratios, 1.0, atol=1e-2):\n",
    "    raise ValueError(\"Warning: Acceptance correction may not be working well, ratios deviate from 1 by more than 1%\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.bar(moment_columns, truth_moment_ratios)\n",
    "ax.set_ylabel(r\"$\\dfrac{\\left(\\frac{H}{Intensity}\\right)_{\\text{acc-corrected}}}{\\left(\\frac{H}{Intensity}\\right)_{\\text{thrown}}} $\", fontsize=18)\n",
    "ax.set_title(\"Ratio of Acceptance Corrected to Thrown Projected Moment Fit Fractions\")\n",
    "ax.set_xticks(range(len(moment_columns)))\n",
    "ax.set_xticklabels(moment_columns, rotation=90)\n",
    "ax.set_ylim(0.9, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d02f6",
   "metadata": {},
   "source": [
    "### Evaluating the Fit Result to the Accepted Monte Carlo\n",
    "With acceptable acceptance-correction from the previous section, we can turn our attention to the fit results in the accepted Monte Carlo. Here we have performed 100 randomized fit results, in which we will only look at the fit result with the best likelihood out of those 100. This \"best fit\" was used to seed 300 bootstrap fits so that we can obtain more reasonable errors on the partial wave results. The projected moments currently have no method for error propagation from the PWA results, so the bootstrap also provides us with projected moment errors we would otherwise lack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39b0e5",
   "metadata": {},
   "source": [
    "#### Accepted Partial Wave Result\n",
    "To understand how the result of our partial wave fit performed, we can compare it to the truth information. We'll do this first for the acceptance-included Monte Carlo, just to avoid any possible issues in the acceptance correction. We'll do the comparison by calculating the weighted residuals\n",
    "$$\n",
    "\\frac{A_{\\text{acc}} - A_{\\text{truth-acc}}}{\\sigma_{A,\\text{acc}}}\n",
    "\\,,\n",
    "$$\n",
    "but to give the values more context, we'll present them alongside the fit fractions and relative uncertainties. If uncertainties are on the same order of their value ($\\sigma_x/x\\approx 1$), then the weighted residual will be quite small, but not as accurate a representation of model performance. We expect high relative uncertainties for extremely small amplitudes though, i.e. amplitudes with a very small fit fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = utils.get_coherent_sums(acc_result.fit_df)[\"eJPmL\"]\n",
    "\n",
    "fit_fractions = []\n",
    "relative_uncertainties = []\n",
    "weighted_residuals = []\n",
    "intensity = acc_result.fit_df.loc[0, \"detected_events\"]\n",
    "\n",
    "for amp in amplitudes:\n",
    "    value = acc_result.fit_df.loc[0, amp]\n",
    "    err = acc_result.bootstrap_df[f\"{amp}\"].std()\n",
    "    fit_frac = value / intensity if intensity != 0 else np.nan\n",
    "    fit_fractions.append(fit_frac)\n",
    "\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan\n",
    "    relative_uncertainties.append(rel_unc)\n",
    "    \n",
    "    true_val = acc_result.truth_df.loc[0, amp]\n",
    "    w_res = (value - true_val) / err if err != 0 else np.nan\n",
    "    weighted_residuals.append(w_res)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "# fit fractions\n",
    "axs[0].bar(amplitudes, fit_fractions, yerr=[\n",
    "    acc_result.bootstrap_df[amp].std() / intensity if intensity != 0 else 0 for amp in amplitudes\n",
    "])\n",
    "axs[0].set_xticks(range(len(amplitudes)))\n",
    "axs[0].set_xticklabels([utils.convert_amp_name(amp) for amp in amplitudes])\n",
    "axs[0].set_ylabel(r\"$|A|^2 /$ Intensity\", fontsize=14)\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "axs[0].set_title(\"Fit Fractions\")\n",
    "\n",
    "# relative uncertainties\n",
    "axs[1].bar(amplitudes, relative_uncertainties)\n",
    "axs[1].set_ylabel(r\"$\\sigma_{|A|^2} ~/~|A|^2$\", fontsize=16)\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "\n",
    "# weighted residuals\n",
    "axs[2].bar(amplitudes, weighted_residuals)\n",
    "axs[2].set_ylabel(r\"$\\frac{A_{\\text{acc}} - A_{\\text{true}}}{\\sigma_{A_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].set_xticks(range(len(amplitudes)))\n",
    "axs[2].set_xticklabels([utils.convert_amp_name(label) for label in amplitudes], rotation=45, ha='right', rotation_mode='anchor')\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals))) - 0.1, max(abs(np.array(weighted_residuals))) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_diffs = list(utils.get_phase_differences(acc_result.fit_df))\n",
    "avg_fit_fractions = []\n",
    "relative_uncertainties_pd = []\n",
    "weighted_residuals = []\n",
    "\n",
    "intensity = acc_result.fit_df.loc[0, \"detected_events\"]\n",
    "for phase_diff in phase_diffs:\n",
    "    # Get the two amplitudes involved in the phase difference to get average fit fraction\n",
    "    amp1, amp2 = phase_diff.split('_')\n",
    "    fit_frac1 = acc_result.fit_df.loc[0, amp1] / intensity if intensity != 0 else np.nan\n",
    "    fit_frac2 = acc_result.fit_df.loc[0, amp2] / intensity if intensity != 0 else np.nan\n",
    "    avg_fit_fractions.append(0.5 * (abs(fit_frac1) + abs(fit_frac2)))\n",
    "\n",
    "    val = acc_result.fit_df.loc[0, phase_diff]    \n",
    "    # Use circular standard deviation for phase differences, but need to convert to radians, then back to degrees\n",
    "    val_err = np.rad2deg(\n",
    "        scipy.stats.circstd(\n",
    "            np.deg2rad(acc_result.bootstrap_df[phase_diff]), low=-np.pi, high=np.pi\n",
    "        )\n",
    "    )\n",
    "    rel_unc = abs(val_err / val) if val != 0 else np.nan\n",
    "    relative_uncertainties_pd.append(rel_unc)\n",
    "\n",
    "    true_val = acc_result.truth_df.loc[0, phase_diff]\n",
    "    w_res = utils.circular_residual(val, true_val, True) / val_err if val_err != 0 else np.nan\n",
    "    weighted_residuals.append(w_res)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(18, 8), sharex=True)\n",
    "\n",
    "axs[0].bar(phase_diffs, avg_fit_fractions)\n",
    "axs[0].set_ylabel(r\"$\\frac{|A_1|^2 + |A_2|^2}{2 \\times \\text{Intensity}}$\", fontsize=20)\n",
    "axs[0].set_title(\"Average Fit Fraction of Amplitudes in Each Phase Difference\")\n",
    "axs[0].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "axs[1].bar(phase_diffs, relative_uncertainties_pd)\n",
    "axs[1].set_ylabel(r\"$\\sigma_{\\eta_{A_1, A_2}} / \\eta_{A_1, A_2}$\", fontsize=20)\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "axs[2].bar(phase_diffs, weighted_residuals)\n",
    "axs[2].set_ylabel(r\"$\\frac{\\eta_{\\text{acc}} - \\eta_{\\text{true}}}{\\sigma_{\\eta_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals))) - 0.1, max(abs(np.array(weighted_residuals))) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "axs[2].set_xticks(range(len(phase_diffs)))\n",
    "axs[2].set_xticklabels([utils.convert_amp_name(phase_diff) for phase_diff in phase_diffs], rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451c4fb",
   "metadata": {},
   "source": [
    "#### Acceptance-Corrected Partial Wave Result\n",
    "Now we can repeat the same procedure, but use the acceptance-corrected version of the values and compare them to the truth thrown values. Remember that we are simply accepting-correcting the values in the previous section, so these are not necessarily different fits being compared. Any issues found in the non-acceptance corrected values will likely persist here. The main component being changed here is that the true values we are comparing to are those from the thrown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47031d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = utils.get_coherent_sums(acc_corrected_result.fit_df)[\"eJPmL\"]\n",
    "\n",
    "fit_fractions = []\n",
    "fit_fractions_err = []\n",
    "relative_uncertainties = []\n",
    "weighted_residuals = []\n",
    "intensity = acc_corrected_result.fit_df.loc[0, \"generated_events\"]\n",
    "true_intensity = acc_corrected_result.truth_df.loc[0, \"generated_events\"]\n",
    "\n",
    "for amp in amplitudes:\n",
    "    value = acc_corrected_result.fit_df.loc[0, amp]\n",
    "    err = acc_corrected_result.bootstrap_df[f\"{amp}\"].std()\n",
    "    fit_frac = value / intensity if intensity != 0 else np.nan\n",
    "    fit_frac_err = err / intensity if intensity != 0 else np.nan\n",
    "    fit_fractions.append(fit_frac)\n",
    "    fit_fractions_err.append(fit_frac_err)\n",
    "\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan\n",
    "    relative_uncertainties.append(rel_unc)\n",
    "\n",
    "    true_val = thrown_result.truth_df.loc[0, amp]\n",
    "    w_res = (fit_frac - (true_val / true_intensity)) / fit_frac_err if fit_frac_err != 0 else np.nan\n",
    "    weighted_residuals.append(w_res)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "# fit fractions\n",
    "axs[0].bar(amplitudes, fit_fractions, yerr=fit_fractions_err)\n",
    "axs[0].set_ylabel(r\"$|A|^2 /$ Intensity\", fontsize=14)\n",
    "axs[0].set_title(\"Fit Fractions\")\n",
    "\n",
    "# relative uncertainties\n",
    "axs[1].bar(amplitudes, relative_uncertainties)\n",
    "axs[1].set_ylabel(r\"$\\sigma_{|A|^2} ~/~|A|^2$\", fontsize=16)\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "\n",
    "# weighted residuals\n",
    "axs[2].bar(amplitudes, weighted_residuals)\n",
    "axs[2].set_ylabel(r\"$\\frac{A'_{\\text{acc}} - A'_{\\text{true}}}{\\sigma_{A'_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].set_xticks(range(len(amplitudes)))\n",
    "axs[2].set_xticklabels([utils.convert_amp_name(label) for label in amplitudes], rotation=45, ha='right', rotation_mode='anchor')\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals))) - 0.1, max(abs(np.array(weighted_residuals))) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_corrected_result.plot.bootstrap().pairplot([0], amplitudes, is_acceptance_corrected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f25371",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_diffs = list(utils.get_phase_differences(acc_corrected_result.fit_df))\n",
    "avg_fit_fractions = []\n",
    "relative_uncertainties_pd = []\n",
    "weighted_residuals = []\n",
    "\n",
    "intensity = acc_corrected_result.fit_df.loc[0, \"generated_events\"]\n",
    "for phase_diff in phase_diffs:\n",
    "    # Get the two amplitudes involved in the phase difference to get average fit fraction\n",
    "    amp1, amp2 = phase_diff.split('_')\n",
    "    fit_frac1 = acc_corrected_result.fit_df.loc[0, amp1] / intensity if intensity != 0 else np.nan\n",
    "    fit_frac2 = acc_corrected_result.fit_df.loc[0, amp2] / intensity if intensity != 0 else np.nan\n",
    "    avg_fit_fractions.append(0.5 * (abs(fit_frac1) + abs(fit_frac2)))\n",
    "\n",
    "    val = acc_corrected_result.fit_df.loc[0, phase_diff]\n",
    "    # Use circular standard deviation for phase differences, but need to convert to radians, then back to degrees\n",
    "    val_err = np.rad2deg(\n",
    "        scipy.stats.circstd(\n",
    "            np.deg2rad(acc_corrected_result.bootstrap_df[phase_diff]), low=-np.pi, high=np.pi\n",
    "        )\n",
    "    )\n",
    "    rel_unc = abs(val_err / val) if val != 0 else np.nan\n",
    "    relative_uncertainties_pd.append(rel_unc)\n",
    "\n",
    "    true_val = thrown_result.truth_df.loc[0, phase_diff]\n",
    "    w_res = utils.circular_residual(val, true_val, True) / val_err if val_err != 0 else np.nan\n",
    "    weighted_residuals.append(w_res)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(18, 8), sharex=True)\n",
    "\n",
    "axs[0].bar(phase_diffs, avg_fit_fractions)\n",
    "axs[0].set_ylabel(r\"$\\frac{|A_1|^2 + |A_2|^2}{2 \\times \\text{Intensity}}$\", fontsize=20)\n",
    "axs[0].set_title(\"Average Fit Fraction of Amplitudes in Each Phase Difference\")\n",
    "axs[0].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "axs[1].bar(phase_diffs, relative_uncertainties_pd)\n",
    "axs[1].set_ylabel(r\"$\\sigma_{\\eta_{A_1, A_2}} / \\eta_{A_1, A_2}$\", fontsize=20)\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "axs[2].bar(phase_diffs, weighted_residuals)\n",
    "axs[2].set_ylabel(r\"$\\frac{\\eta_{\\text{acc}} - \\eta_{\\text{true}}}{\\sigma_{\\eta_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals))) - 0.1, max(abs(np.array(weighted_residuals))) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "axs[2].set_xticks(range(len(phase_diffs)))\n",
    "axs[2].set_xticklabels([utils.convert_amp_name(phase_diff) for phase_diff in phase_diffs], rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_corrected_result.plot.bootstrap().pairplot([0], phase_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0df1f",
   "metadata": {},
   "source": [
    "#### Acceptance Corrected Projected Moments\n",
    "We can now compare how the acceptance-corrected projected moments compare to the true thrown projected moments. If our partial wave model did not resolve to the true values, but the projected moments do, then it may hint at an ambiguous solution. If our moments do not match though, then it indicates we have simply not obtained the best solution. We'll prescribe the same method, checking the normalized moments $H' = H/H^0(0,0,0,0)$ (similar to a fit fraction due to $H^0(0,0,0,0) =$ # of events), relative uncertainty, and weighted residual with respect to the true thrown projected moments.\n",
    "\n",
    "Due to the mismatch in the number of events between thrown and acceptance-corrected data, we'll need to use the normalized moments in the weighted residual as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [col for col in thrown_result.truth_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "\n",
    "fit_fractions = []\n",
    "fit_fractions_err = []\n",
    "relative_uncertainties = []\n",
    "weighted_residuals = []\n",
    "\n",
    "H0_0000 = acc_corrected_result.proj_moments_df.loc[0, \"H0_0000\"]\n",
    "true_H0_0000 = thrown_result.truth_proj_moments_df.loc[0, \"H0_0000\"]\n",
    "for mom in moments:\n",
    "    value = acc_corrected_result.proj_moments_df.loc[0, mom]\n",
    "    err = acc_corrected_result.bootstrap_proj_moments_df[mom].std()\n",
    "\n",
    "    fit_frac = value / H0_0000 if H0_0000 != 0 else np.nan\n",
    "    fit_frac_err = err / H0_0000 if H0_0000 != 0 else np.nan\n",
    "    fit_fractions.append(fit_frac)\n",
    "    fit_fractions_err.append(fit_frac_err)\n",
    "\n",
    "    rel_unc = abs(err / value) if value != 0 else np.nan    \n",
    "    relative_uncertainties.append(rel_unc)\n",
    "\n",
    "    true_val = thrown_result.truth_proj_moments_df.loc[0, mom]\n",
    "    w_res = (fit_frac - (true_val / true_H0_0000)) / fit_frac_err if fit_frac_err != 0 else np.nan\n",
    "    weighted_residuals.append(w_res)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "# normalized moments\n",
    "axs[0].bar(moments, np.abs(np.array(fit_fractions)), yerr=fit_fractions_err) # use absolute value so we can plot on log scale\n",
    "axs[0].set_ylabel(r\"$|H ~/~ H0\\_0000|$ \")\n",
    "axs[0].set_title(\"Normalized Moments\")\n",
    "axs[0].set_yscale('log') # plot log since some moments are very tiny\n",
    "\n",
    "# relative uncertainties\n",
    "axs[1].bar(moments, relative_uncertainties)\n",
    "axs[1].set_ylabel(r\"$\\sigma_{H} ~/~ H$\")\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "axs[2].bar(moments, weighted_residuals)\n",
    "axs[2].set_ylabel(r\"$\\frac{H'_{\\text{acc}} - H'_{\\text{true}}}{\\sigma_{H'_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals))) - 0.1, max(abs(np.array(weighted_residuals))) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "axs[2].set_xticks(range(len(moments)))\n",
    "axs[2].set_xticklabels([utils.convert_moment_name(mom) for mom in moments], rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6190fb",
   "metadata": {},
   "source": [
    "Some of these moments are clearly very small, and so it may not be realistic to expect that we project their values well. Lets look at just the moments whose normalized values are \"signficant\" $|H/H^0(0000)| > 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0da967",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [col for col in thrown_result.truth_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "\n",
    "true_fit_fractions = [thrown_result.truth_proj_moments_df.loc[0, mom] / thrown_result.truth_proj_moments_df.loc[0, \"H0_0000\"] for mom in moments]\n",
    "\n",
    "mask = np.abs(np.array(true_fit_fractions)) > 0.01\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 6), sharex=True)\n",
    "\n",
    "# normalized moments\n",
    "axs[0].bar(np.array(moments)[mask], np.abs(np.array(fit_fractions)[mask]), yerr=np.array(fit_fractions_err)[mask]) # use absolute value so we can plot on log scale\n",
    "axs[0].set_ylabel(r\"$|H ~/~ H0\\_0000|$ \")\n",
    "axs[0].set_title(\"Normalized Moments\")\n",
    "axs[0].set_yscale('log') # plot log since some moments are very tiny\n",
    "\n",
    "# relative uncertainties\n",
    "axs[1].bar(np.array(moments)[mask], np.array(relative_uncertainties)[mask])\n",
    "axs[1].set_ylabel(r\"$\\sigma_{H} ~/~ H$\")\n",
    "axs[1].set_title(\"Relative Uncertainty\")\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "axs[2].bar(np.array(moments)[mask], np.array(weighted_residuals)[mask])\n",
    "axs[2].set_ylabel(r\"$\\frac{H'_{\\text{acc}} - H'_{\\text{true}}}{\\sigma_{H'_{\\text{acc}}}}$\", fontsize=20)\n",
    "axs[2].axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "axs[2].axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "axs[2].set_ylim(-max(abs(np.array(weighted_residuals)[mask])) - 0.1, max(abs(np.array(weighted_residuals)[mask])) + 0.1)\n",
    "axs[2].set_title(rf\"Weighted Residuals\")\n",
    "axs[2].set_xticks(range(len(np.array(moments)[mask])))\n",
    "axs[2].set_xticklabels([utils.convert_moment_name(mom) for mom in np.array(moments)[mask]], rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fb6b1",
   "metadata": {},
   "source": [
    "### Evaluating Randomized Fits with Moments\n",
    "As an added bonus, we can use the moments to see whether our best fit is truly a unique result. We can do this by comparing the $\\Delta\\ln\\mathscr{L}$ vs $\\chi^2_{H} / ndf$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [col for col in acc_corrected_result.randomized_proj_moments_df.columns if col.startswith(\"H\")]\n",
    "# using acc_corrected result since moments are always acceptance corrected, so they're comparable to rand projected moments\n",
    "best_moments = acc_corrected_result.proj_moments_df.loc[0, moments].values\n",
    "best_moments_err = acc_corrected_result.bootstrap_proj_moments_df[moments].std().values\n",
    "best_likelihood = acc_corrected_result.fit_df.loc[0, \"likelihood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16054ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_averaged_residuals = []\n",
    "rand_likelihoods = []\n",
    "\n",
    "for i in range(len(acc_corrected_result.randomized_proj_moments_df)):\n",
    "    rand_moments = acc_corrected_result.randomized_proj_moments_df.loc[i, moments].values\n",
    "\n",
    "    squared_weighted_residual = (\n",
    "        np.sum(\n",
    "            ((best_moments - rand_moments) ** 2) / (best_moments_err)**2)\n",
    "    ) / len(moments)\n",
    "    moment_averaged_residuals.append(squared_weighted_residual)\n",
    "\n",
    "    rand_likelihood = acc_corrected_result.randomized_df.loc[i, \"likelihood\"]\n",
    "    rand_likelihoods.append(rand_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in likelihood between the best and each randomized fit\n",
    "delta_lnL = [ll - best_likelihood for ll in rand_likelihoods]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(delta_lnL, moment_averaged_residuals, c='tab:blue', s=20, alpha=0.7)\n",
    "plt.xlabel(r'$\\Delta \\ln \\mathcal{L}$ (randomized - best)', fontsize=14)\n",
    "plt.ylabel(r'$\\frac{1}{n}\\sum^n \\frac{(H_n^{\\text{best}} - H_n^{\\text{rand}})^2}{(\\sigma_{H_n}^{\\text{best}})^2}$', fontsize=25)\n",
    "plt.title(r'$\\Delta \\ln \\mathcal{L}$ vs. $\\chi^2_{H}$ for Randomized Fits', fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e95998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices in randomized_df where likelihood is approximately -41645.6 (2nd best value)\n",
    "matching_indices = acc_corrected_result.randomized_df.index[\n",
    "    np.isclose(acc_corrected_result.randomized_df[\"likelihood\"], -41645.6)\n",
    "]\n",
    "\n",
    "# Select corresponding rows from randomized_proj_moments_df\n",
    "matching_proj_moments = acc_corrected_result.randomized_proj_moments_df.loc[matching_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6364b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weighted residuals for each matching_proj_moments using the best fit as the comparison\n",
    "for i in range(len(matching_proj_moments)):\n",
    "    rand_moments = matching_proj_moments.iloc[i][moments].values\n",
    "    # Avoid division by zero in error    \n",
    "    weighted_residual = (best_moments - rand_moments) / best_moments_err\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(moments, weighted_residual)\n",
    "    plt.axhline(0, color='k', linestyle='-', linewidth=1)\n",
    "    plt.axhline(3, color='r', linestyle='--', linewidth=1)\n",
    "    plt.axhline(-3, color='r', linestyle='--', linewidth=1)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(r'Weighted Residual: $(H^{\\text{best}} - H^{\\text{rand}})/\\sigma_{H^{\\text{best}}}$', fontsize=16)\n",
    "    plt.title(f'Weighted Residuals: Best Fit vs. Randomized Fit {matching_indices[i]}', fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
