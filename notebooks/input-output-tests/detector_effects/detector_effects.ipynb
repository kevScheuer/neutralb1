{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Detector Effects Break $\\omega\\pi^0$ Amplitude Analysis?\n",
    "Initial input output tests in $\\omega\\pi^0$ are showing bin-to-bin inconsistencies in fit results from an amplitude analysis. The goal of this notebook will be to determine where these inconsistencies are sourced from so that we may go about solving them.\n",
    "\n",
    "Questions: \n",
    "1. **What detector effects are most detrimental to the amplitude analysis results?**\n",
    "2. **Does the AmpTools efficiency calculation impact fit performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To test this, we will be conducting input-output tests using [$\\omega\\pi^0$ Monte Carlo signal and phasespace files.](https://halldweb.jlab.org/wiki-private/index.php/Omega_Pi_Simulation_Samples_Version_3#Neutral_signal_versionsver3.1). We'll perform the amplitude analysis in independent bins of $\\omega\\pi^0$ invariant mass, and the \"output\" fit results in each bin are compared to the generated \"input\" values we expect the fit to successfully converge to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect Options\n",
    "Through the DSelector, we have access to a wide array of options to turn on / off effects of our detector simulation. These are:\n",
    "1. **Detector Acceptance:** applies the detector efficiency to events \n",
    "2. **Reconstruction:** An algorithm uses the hits within the detector to reconstruct the particle tracks from the decay. This effectively \"smears\" the particle 4-momenta with detector resolution effects and reconstruction error\n",
    "3. **Misidentification & Combinatorics:** Allow ourselves to \"forget\" the origin and exact ID of each particle, and rely on the kinematic fitter and our cuts to do this instead.\n",
    "4. **Out-of-time photons (Oot $\\gamma$):** simulates background photon \"sidebands\" that are statistically subtracted to obtain the photon that generated the event. This option can be combined with any of the above effects\n",
    "\n",
    "By performing an amplitude analysis to datasets produced from these options, we can determine which effect is most detrimental to the fit result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Input\n",
    "Input files are obtained by passing the Monte Carlo ROOT trees through a DSelector, using a standard set of cuts. Depending on what detector effects we include some of these cuts are turned on/off. For example, if we don't want to include out-of-time photons then we do not utilize an RF sideband subtraction, since we know for certain what photon generated the event. For each detector effect situation, we then have a data file for the entire $\\omega\\pi^0$ mass range. To obtain the files for the mass-independent fits, we copy the trees to each bin and apply cuts on the $-t$, $\\gamma_{\\text{beam}}$, and $M_{\\omega\\pi^0}$ values. Note that an extra cut is included on the invariant mass of the $p\\pi^0$ pair as well, requiring $M_{p\\pi^0} > 1.4~GeV$. This cut is applied in real data to remove the $\\Delta^+$ baryon contribution. We don't generate the $\\Delta^+$ in our MC and so do not strictly *need* this cut, but past work has indicated that leaving this cut in is not detrimental to the fit results.\n",
    "\n",
    "The data files, now portioned into bins of $\\omega\\pi^0$ mass, allow us to calculate the detector efficiency $\\eta_{\\text{data}}$ in each bin. We have a data file for the \"thrown\" case, in which no detector effects are applied, and so dividing any dataset by this tells us the efficiency of our detector:\n",
    "\n",
    "$$\\eta_{\\text{data}} = \\frac{\\text{Events}_{~\\text{gen}}}{\\text{Events}_{~\\text{detected}}}$$\n",
    "\n",
    "With the data files ready for PWA, we arrive at a problem. The \"true\" production parameters that the Monte Carlo was generated with originate from a mass-dependent fit, applied over the entire $\\omega\\pi^0$ mass range, but to plot the generated values we need the parameter values for individual bins so that we may determine how well a fit performed. To obtain these **truth fits** we do the following:\n",
    "1. Create a config file that has all its amplitude parameters fixed to the generated values. Include the same fixed Breit-Wigner functions from the original mass-dependent fit in the config file as well.\n",
    "2. Perform a \"fit\" in each $\\omega\\pi^0$ mass bin with this entirely fixed config file. The Breit-Wigner function will then weight the production parameters for that particular mass bin. For example, this ensures the $b_1(1235)$ is strongest in the 1.22 - 1.24 GeV bin, but has effectively zeroed out by 2.0 GeV.\n",
    "3. Lastly the overall scaling of the production parameters is sensitive to the number of events in the original mass-dependent fit. So we introduce one free floating `scale` factor, that multiplies every amplitude in the cfg file. This allows the fit to adjust the overall scaling to match the events in each bin\n",
    "\n",
    "The additional advantage of running a fit like this, is that all the coherent sum calculations can be done using AmpTools `FitResults` class on the output `.fit` files. We can produce dataframes that allow us to plot the *true* values we generated for any amplitude, and directly evaluate our fit performance relative to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Output\n",
    "The outputs of this study will be \"truth-initialized\" fits, where each bin begins at the generated value for that bin. This means the production parameters are all initialized to the true values, but allowed to float in MINUIT's minimization process. Once again, the overall magnitude of the parameters are sensitive to the number of events originally generated, and so we need to scale them to properly begin at the right likelihood value. Luckily, this `scale` factor has already been computed for us when we did the truth fits, and so this factor is imported for each bin and multiplies all the production coefficients.\n",
    "\n",
    "To calculate the fit results' efficiency\n",
    "$$\\eta_{\\text{fit}} = \\frac{\\text{Events}_{~\\text{gen}}}{\\text{Events}_{~\\text{detected}}}$$\n",
    "we can use AmpTools' `FitResults.intensity` function to properly calculate the detected and generated intensity in each bin. This will not necessarily match $\\eta_{\\text{data}}$ since AmpTools approximates an intensity integral using an average value calculated from phasespace files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, lets load all our packages and paths needed for each analysis section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "parent_dir = str(Path().resolve().parents[2])\n",
    "working_dir = f\"{parent_dir}/analysis/input-output-tests/detector_effects/\"\n",
    "sys.path.insert(0, parent_dir)\n",
    "import analysis.scripts.pwa_tools as pwa_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector Effect Analysis\n",
    "As discussed, we have a wide array of combinations to choose from to simulate our detector effects. This section will go through each one of interest and produce plots to view fit results and determine relations between them and the efficiencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pwa Plotter class, we'll need to quickly define some custom functions for obtaining and plotting the efficiencies and any correlation the efficiency has with amplitude pull distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in default matplotlib style\n",
    "plt.style.use(\"/w/halld-scshelf2101/kscheuer/neutralb1/analysis/scripts/pwa_plotter.mplstyle\")\n",
    "\n",
    "def get_fit_efficiency(fit_file: pd.DataFrame) -> Tuple[float,float]:\n",
    "    # Get the efficiency and its error from a fit file\n",
    "    eff = fit_file[\"detected_events\"] / fit_file[\"generated_events\"]\n",
    "    eff_err = eff * np.sqrt(\n",
    "        np.square(fit_file[\"detected_events_err\"] / fit_file[\"detected_events\"]) +\n",
    "        np.square(fit_file[\"generated_events_err\"] / fit_file[\"generated_events\"])\n",
    "    )\n",
    "    return eff, eff_err\n",
    "\n",
    "\n",
    "def get_data_efficiency(acc_file: pd.DataFrame, gen_file: pd.DataFrame) -> Tuple[float,float]:\n",
    "    # Get the efficiency and its error from a data file\n",
    "    eff = acc_file[\"bin_contents\"] / gen_file[\"bin_contents\"]\n",
    "    eff_err = eff * np.sqrt(\n",
    "        np.square(acc_file[\"bin_error\"] / acc_file[\"bin_contents\"]) +\n",
    "        np.square(gen_file[\"bin_error\"] / gen_file[\"bin_contents\"])\n",
    "    )\n",
    "    return eff, eff_err\n",
    "\n",
    "\n",
    "def plot_efficiency(fit_df, acc_df, gen_df):\n",
    "    # Plot efficiency as function of omega-pi0 mass\n",
    "\n",
    "    fit_eff, fit_eff_err = get_fit_efficiency(fit_df)\n",
    "    data_eff, data_eff_err = get_data_efficiency(acc_df, gen_df)\n",
    "    \n",
    "    mass_bins = gen_df[\"mass_mean\"]\n",
    "    bin_width = (gen_df[\"mass_high_edge\"] - gen_df[\"mass_low_edge\"])[0]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.errorbar(\n",
    "        x=mass_bins, y=data_eff, xerr=bin_width/2., yerr=data_eff_err,\n",
    "        marker=\".\", linestyle=\"\", color=\"black\", label=r\"$\\eta_{~\\text{data}}$\"\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        x=mass_bins, y=fit_eff, xerr=bin_width/2., yerr=fit_eff_err, \n",
    "        marker=\".\", linestyle=\"\", color=\"red\", label=r\"$\\eta_{~\\text{fit}}$\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r\"$\\omega\\pi^0$ inv. mass $(GeV)$\", loc=\"right\")\n",
    "    ax.set_ylabel(f\"Efficiency / 0.02 GeV\", loc=\"top\")\n",
    "\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_jp_efficiency(fit_df, acc_df, gen_df, truth_df):\n",
    "    # Plot difference of efficiencies as function of omega-pi0 mass with JP values\n",
    "    # Essentially a copy of the mass_phase function in the pwa_tools module\n",
    "\n",
    "    # grab the efficiencies and their errors\n",
    "    fit_eff, fit_eff_err = get_fit_efficiency(fit_df)\n",
    "    data_eff, data_eff_err = get_data_efficiency(acc_df, gen_df)\n",
    "    \n",
    "    # calculate the difference between the two efficiencies with their errors\n",
    "    diff_eff = data_eff - fit_eff\n",
    "    diff_eff_err = np.sqrt(\n",
    "        np.square(data_eff_err) + np.square(fit_eff_err)\n",
    "    )\n",
    "\n",
    "    # grab the mass bins and widths\n",
    "    mass_bins = gen_df[\"mass_mean\"]\n",
    "    bin_width = (gen_df[\"mass_high_edge\"] - gen_df[\"mass_low_edge\"])[0]\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        2, 1,\n",
    "        sharex=True,\n",
    "        gridspec_kw={\"wspace\": 0.0, \"hspace\": 0.07},\n",
    "        height_ratios=[3, 1],\n",
    "    )\n",
    "\n",
    "    # ---AXS 0---\n",
    "    # plot data points\n",
    "    axs[0].errorbar(\n",
    "        x=mass_bins, y=acc_df[\"bin_contents\"], xerr=bin_width/2., yerr=acc_df[\"bin_error\"],        \n",
    "        fmt=\"k.\", label=\"MC Events\",\n",
    "    )\n",
    "    # plot fit result as gray histogram\n",
    "    axs[0].bar(\n",
    "        x=mass_bins, height=fit_df[\"detected_events\"], width=bin_width,            \n",
    "        color=\"0.1\", alpha=0.15, label=\"Fit Result\"\n",
    "    )\n",
    "    axs[0].errorbar(\n",
    "        x=mass_bins, y=fit_df[\"detected_events\"], yerr=fit_df[\"detected_events_err\"],\n",
    "        fmt=\",\", color=\"0.1\", alpha=0.2, markersize=0,\n",
    "    )\n",
    "\n",
    "    # plot the JP values, hardcoded since we know what JP are present\n",
    "    colors = matplotlib.colormaps[\"Dark2\"].colors # use the same colors as the pwa Plotter\n",
    "    axs[0].errorbar( # 1+\n",
    "        x=mass_bins, y=fit_df[\"1p\"], xerr=bin_width/2., yerr=fit_df[\"1p_err\"],\n",
    "        marker=\"o\", markersize=6, linestyle=\"\", color=colors[2], label=r\"$1^{+}$\"\n",
    "    )\n",
    "    axs[0].plot( # 1+ truth\n",
    "        mass_bins, truth_df[\"1p\"], \n",
    "        linestyle=\"-\", marker=\"\", color=colors[2],\n",
    "    )\n",
    "    axs[0].errorbar( # 1-\n",
    "        x=mass_bins, y=fit_df[\"1m\"], xerr=bin_width/2., yerr=fit_df[\"1m_err\"],\n",
    "        marker=\"s\", markersize=6, linestyle=\"\", color=colors[3], label=r\"$1^{-}$\"\n",
    "    )\n",
    "    axs[0].plot( # 1- truth\n",
    "        mass_bins, truth_df[\"1m\"], \n",
    "        linestyle=\"-\", marker=\"\", color=colors[3],\n",
    "    )\n",
    "\n",
    "\n",
    "    axs[0].set_ylabel(f\"Events / {bin_width:.3f} GeV\", loc=\"top\")\n",
    "    axs[0].set_ylim(bottom=0.0)\n",
    "\n",
    "    # ---AXS 1---\n",
    "    # plot the efficiency difference\n",
    "    axs[1].errorbar(\n",
    "        x=mass_bins, y=diff_eff, xerr=bin_width/2., yerr=diff_eff_err,\n",
    "        marker=\".\", linestyle=\"\", color=\"black\"\n",
    "    )\n",
    "    axs[1].axhline(0, color=\"black\", linestyle=\"-\")\n",
    "\n",
    "    axs[1].set_xlabel(r\"$\\omega\\pi^0$ inv. mass $(GeV)$\", loc=\"right\")\n",
    "    axs[1].set_ylabel(r\"$\\Delta \\eta$\", loc=\"center\")\n",
    "\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def plot_correlation(fit_df, acc_df, gen_df, truth_df, columns: List[str]) -> None:\n",
    "    # Plot the correlation between the efficiency difference and the pull magnitude of the columns\n",
    "\n",
    "    # check if the columns are present in the dataframes\n",
    "    for col in columns:\n",
    "        if col not in fit_df.columns:\n",
    "            print(f\"WARNING: Column {col} not present in the fit_df, exiting\")\n",
    "            return\n",
    "        if col not in truth_df.columns:\n",
    "            print(f\"WARNING: Column {col} not present in the truth_df, exiting\")\n",
    "            return\n",
    "\n",
    "    # calculate the difference between the two efficiencies\n",
    "    fit_eff, _ = get_fit_efficiency(fit_df)    \n",
    "    data_eff, _ = get_data_efficiency(acc_df, gen_df)    \n",
    "    diff_eff = data_eff - fit_eff    \n",
    "\n",
    "    if diff_eff.eq(0).all():\n",
    "        print(\"WARNING: All efficiency differences are zero, returning 0 correlation\")    \n",
    "        corr = 0 \n",
    "\n",
    "    # plot the correlation between the efficiency difference and the pull magnitude of each column\n",
    "    for col in columns:\n",
    "        pull = ((fit_df[col] - truth_df[col]) / fit_df[f\"{col}_err\"]).abs()\n",
    "\n",
    "        if np.isnan(pull).any():\n",
    "            print(f\"WARNING: NaN values in pull, skipping column {col}\")\n",
    "            continue           \n",
    "        if not diff_eff.eq(0).all():\n",
    "            corr = np.corrcoef(diff_eff, pull)[0,1]\n",
    "\n",
    "        plt.scatter(diff_eff, pull, marker=\".\", label=f\"{pwa_tools.convert_amp_name(col)}: r={corr:.3f}\")\n",
    "        \n",
    "    plt.xlabel(r\"$\\Delta \\eta$\", loc=\"right\")\n",
    "    plt.ylabel(r\"$|~\\text{pull}~|$\", loc=\"top\")\n",
    "    plt.minorticks_on()    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the thrown file, as its common to all the sections below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_data = pd.read_csv(f\"{working_dir}/thrown/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Detector (no effects)\n",
    "Two simple plots we can make for these input-output tests are of the individual wave contributions vs. their truth info. The plots are organized with $J^P\\ell$ values by row, and $m$-projections by column, with the corresponding reflectivities $\\varepsilon$ in each plot. Solid lines indicate the generated values we expect the fits to converge to, and the individual data points are the mass-independent fit results in those bins. The first plot shows the intensity for each wave, and the second the fit fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_fit = pd.read_csv(f\"{working_dir}/thrown/fit.csv\", index_col=\"index\")\n",
    "thrown_truth = pd.read_csv(f\"{working_dir}/thrown/truth.csv\", index_col=\"index\")\n",
    "# no accepted data since the thrown data is the \"accepted\" data\n",
    "\n",
    "thrown_plotter = pwa_tools.Plotter(thrown_fit, thrown_data, truth_df=thrown_truth)\n",
    "thrown_plotter.intensities()\n",
    "thrown_plotter.intensities(True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efficiency Plots (safe to skip fot this ideal scenario)\n",
    "The following efficiency plots for the *no affects* situation is not insightful, as there is no acceptance that would create a different efficiency value. They are simply included for completeness. See **Detector Acceptance** for how to interpret them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jp_efficiency(thrown_fit, thrown_data, thrown_data, thrown_truth)\n",
    "plot_efficiency(thrown_fit, thrown_data, thrown_data)\n",
    "plot_correlation(thrown_fit, thrown_data, thrown_data, thrown_truth, [\"1p\", \"1m\"])\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(thrown_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(thrown_fit, thrown_data, thrown_data, thrown_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Acceptance\n",
    "Now that detector acceptance is included, we can better study how efficiency $\\eta$ may be connected to fit result issues. We can first compare $\\eta_{\\text{data}}$ vs $\\eta_{\\text{fit}}$ to directly compare how well each matches, and look for large jumps bin-to-bin. We can then calculate $\\Delta \\eta$ and view its relation to the $J^P$ coherent sum results.\n",
    "\n",
    "To quantify the correlation between $\\Delta \\eta$ and bin issues, we can calculate a pull:\n",
    "$$\\text{pull} = \\frac{\\text{fit }-\\text{gen}}{\\sigma_{\\text{fit}}}$$\n",
    "which quantifies how far our fit results diverge from the starting (generated) value. We can then calculate a correlation coefficient $r$ between $|\\text{pull}|$ and $\\Delta\\eta$. This is done for the $J^P$ coherent sums, and the individual amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_noaccid_data = pd.read_csv(f\"{working_dir}/accept_noaccidental/data.csv\")\n",
    "acc_noaccid_fit = pd.read_csv(f\"{working_dir}/accept_noaccidental/fit.csv\", index_col=\"index\")\n",
    "acc_noaccid_truth = pd.read_csv(f\"{working_dir}/accept_noaccidental/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_noaccid_plotter = pwa_tools.Plotter(acc_noaccid_fit, acc_noaccid_data, truth_df=acc_noaccid_truth)\n",
    "\n",
    "plot_efficiency(acc_noaccid_fit, acc_noaccid_data, thrown_data)\n",
    "plot_jp_efficiency(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth)\n",
    "plot_correlation(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth, [\"1p\", \"1m\"])\n",
    "\n",
    "acc_noaccid_plotter.intensities()\n",
    "acc_noaccid_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(acc_noaccid_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Acceptance & Out-of-time $\\gamma$\n",
    "Out-of-time $\\gamma$ refers to the beam photon 4-vector not strictly being the one that generated the event, and so a sideband subtraction is performed to remove out of time photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = pd.read_csv(f\"{working_dir}/accept/data.csv\")\n",
    "acc_fit = pd.read_csv(f\"{working_dir}/accept/fit.csv\", index_col=\"index\")\n",
    "acc_truth = pd.read_csv(f\"{working_dir}/accept/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_plotter = pwa_tools.Plotter(acc_fit, acc_data, truth_df=acc_truth)\n",
    "\n",
    "plot_efficiency(acc_fit, acc_data, thrown_data)\n",
    "plot_jp_efficiency(acc_fit, acc_data, thrown_data, acc_truth)\n",
    "plot_correlation(acc_fit, acc_data, thrown_data, acc_truth, [\"1p\", \"1m\"])\n",
    "\n",
    "acc_plotter.intensities()\n",
    "acc_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(acc_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(acc_fit, acc_data, thrown_data, acc_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceptance and Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_noacc_fit = pd.read_csv(f\"{working_dir}/matched_noaccidental/fit.csv\", index_col=\"index\")\n",
    "matched_noacc_truth = pd.read_csv(f\"{working_dir}/matched_noaccidental/truth.csv\", index_col=\"index\")\n",
    "matched_noacc_data = pd.read_csv(f\"{working_dir}/matched_noaccidental/data.csv\")\n",
    "\n",
    "matched_noacc_plotter = pwa_tools.Plotter(matched_noacc_fit, matched_noacc_data, truth_df=matched_noacc_truth)\n",
    "\n",
    "plot_efficiency(matched_noacc_fit, matched_noacc_data, thrown_data)\n",
    "plot_jp_efficiency(matched_noacc_fit, matched_noacc_data, thrown_data, matched_noacc_truth)\n",
    "plot_correlation(matched_noacc_fit, matched_noacc_data, thrown_data, matched_noacc_truth, [\"1p\", \"1m\"])\n",
    "matched_noacc_plotter.intensities()\n",
    "matched_noacc_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(matched_noacc_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(matched_noacc_fit, matched_noacc_data, thrown_data, matched_noacc_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceptance, Reconstruction, and Out-of-time $\\gamma$\n",
    "For whatever reason, the 1.42 - 1.44 $\\omega\\pi^0$ mass bin just refuses to converge. For the time being, lets just ignore it and drop out the corresponding rows as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_fit = pd.read_csv(f\"{working_dir}/matched/fit.csv\", index_col=\"index\")\n",
    "matched_truth = pd.read_csv(f\"{working_dir}/matched/truth.csv\", index_col=\"index\")\n",
    "matched_data = pd.read_csv(f\"{working_dir}/matched/data.csv\")\n",
    "\n",
    "# drop the 1.42 - 1.44 bin\n",
    "matched_truth.drop(21, inplace=True)\n",
    "matched_truth.reset_index(drop=True, inplace=True)\n",
    "matched_data.drop(21, inplace=True)\n",
    "matched_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dropped_thrown = thrown_data.copy()\n",
    "dropped_thrown.drop(21, inplace=True)\n",
    "dropped_thrown.reset_index(drop=True, inplace=True)\n",
    "\n",
    "matched_plotter = pwa_tools.Plotter(matched_fit, matched_data, truth_df=matched_truth)\n",
    "\n",
    "plot_efficiency(matched_fit, matched_data, dropped_thrown)\n",
    "plot_jp_efficiency(matched_fit, matched_data, dropped_thrown, matched_truth)\n",
    "plot_correlation(matched_fit, matched_data, dropped_thrown, matched_truth, [\"1p\", \"1m\"])\n",
    "matched_plotter.intensities()\n",
    "matched_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(matched_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(matched_fit, matched_data, dropped_thrown, matched_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Effects *Except* Out-of-time $\\gamma$\n",
    "This includes detector acceptance, resolution from reconstruction, combinatorics / Mis-ID, but does *not* use any sideband subtraction for the beam photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noacc_fit = pd.read_csv(f\"{working_dir}/noaccidental/fit.csv\", index_col=\"index\")\n",
    "noacc_truth = pd.read_csv(f\"{working_dir}/noaccidental/truth.csv\", index_col=\"index\")\n",
    "noacc_data = pd.read_csv(f\"{working_dir}/noaccidental/data.csv\")\n",
    "\n",
    "noacc_plotter = pwa_tools.Plotter(noacc_fit, noacc_data, truth_df=noacc_truth)\n",
    "\n",
    "plot_efficiency(noacc_fit, noacc_data, thrown_data)\n",
    "plot_jp_efficiency(noacc_fit, noacc_data, thrown_data, noacc_truth)\n",
    "plot_correlation(noacc_fit, noacc_data, thrown_data, noacc_truth, [\"1p\", \"1m\"])\n",
    "noacc_plotter.intensities()\n",
    "noacc_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(noacc_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(noacc_fit, noacc_data, thrown_data, noacc_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Effects Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fit = pd.read_csv(f\"{working_dir}/all_effects/fit.csv\", index_col=\"index\")\n",
    "all_truth = pd.read_csv(f\"{working_dir}/all_effects/truth.csv\", index_col=\"index\")\n",
    "all_data = pd.read_csv(f\"{working_dir}/all_effects/data.csv\")\n",
    "\n",
    "all_effects_plotter = pwa_tools.Plotter(all_fit, all_data, truth_df=all_truth)\n",
    "\n",
    "plot_efficiency(all_fit, all_data, thrown_data)\n",
    "plot_jp_efficiency(all_fit, all_data, thrown_data, all_truth)\n",
    "plot_correlation(all_fit, all_data, thrown_data, all_truth, [\"1p\", \"1m\"])\n",
    "all_effects_plotter.intensities()\n",
    "all_effects_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(all_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(all_fit, all_data, thrown_data, all_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Out-of-time $\\gamma$\n",
    "Appears that the out of time photons degrades the fit results for each situation, but we'll need to affirm this through some quantitative factor. Lets compare the averaged absolute pull values for $K$ different values in $N$ mass bins\n",
    "$$\n",
    "|\\overline{p}| = \\frac{1}{N} \\sum_{i}^{N} \n",
    "\\frac{1}{K}\n",
    "\\sum_{k}^{K}\n",
    "\\left| \n",
    "    \\frac{(\\text{fit param }k)_i - (\\text{gen param }k)_i}{\\sigma_{(\\text{fit }k)_i}} \n",
    "\\right|\n",
    "$$\n",
    "and calculate\n",
    "$$\n",
    "\\Delta |\\overline{p}| = |\\overline{p}|_{\\text{single }\\gamma} - |\\overline{p}|_{\\text{oot }\\gamma}\n",
    "$$\n",
    "to measure how the pulls differ on average before and after the out-of-time $\\gamma$ effects are applied. We are using the absolute value so as to avoid negative pulls incorrectly removing positive pull values. This ensures we are truly measuring how much the fit diverges from the true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_absolute_pull(fit_df, truth_df, columns: List[str]) -> float:\n",
    "    # Calculate the averaged absolute pull for the columns\n",
    "    pull = 0\n",
    "    # get the average of the pull magnitudes for the columns\n",
    "    for col in columns:\n",
    "        pull += ((fit_df[col] - truth_df[col]) / fit_df[f\"{col}_err\"]).abs()\n",
    "    pull /= len(columns)    \n",
    "\n",
    "    return pull.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_noaccid_data = pd.read_csv(f\"{working_dir}/accept_noaccidental/data.csv\")\n",
    "acc_noaccid_fit = pd.read_csv(f\"{working_dir}/accept_noaccidental/fit.csv\", index_col=\"index\")\n",
    "acc_noaccid_truth = pd.read_csv(f\"{working_dir}/accept_noaccidental/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_data = pd.read_csv(f\"{working_dir}/accept/data.csv\")\n",
    "acc_fit = pd.read_csv(f\"{working_dir}/accept/fit.csv\", index_col=\"index\")\n",
    "acc_truth = pd.read_csv(f\"{working_dir}/accept/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_noaccid_plotter = pwa_tools.Plotter(acc_noaccid_fit, acc_noaccid_data, truth_df=acc_noaccid_truth)\n",
    "acc_plotter = pwa_tools.Plotter(acc_fit, acc_data, truth_df=acc_truth)\n",
    "\n",
    "acc_noaccid_pull = average_absolute_pull(acc_noaccid_fit, acc_noaccid_truth, [\"1p\", \"1m\"])\n",
    "acc_pull = average_absolute_pull(acc_fit, acc_truth, [\"1p\", \"1m\"])\n",
    "print(f\"{\"-\"*30}\")\n",
    "print(f\"With no background: {acc_noaccid_pull}\")\n",
    "print(f\"With out of time photons: {acc_pull}\")\n",
    "print(f\"Difference: {acc_noaccid_pull - acc_pull}\")\n",
    "print(f\"{\"-\"*30}\")\n",
    "\n",
    "acc_noaccid_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)\n",
    "acc_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_noaccid_fit = pd.read_csv(f\"{working_dir}/matched_noaccidental/fit.csv\", index_col=\"index\")\n",
    "matched_noaccid_truth = pd.read_csv(f\"{working_dir}/matched_noaccidental/truth.csv\", index_col=\"index\")\n",
    "matched_noaccid_data = pd.read_csv(f\"{working_dir}/matched_noaccidental/data.csv\")\n",
    "\n",
    "matched_fit = pd.read_csv(f\"{working_dir}/matched/fit.csv\", index_col=\"index\")\n",
    "matched_truth = pd.read_csv(f\"{working_dir}/matched/truth.csv\", index_col=\"index\")\n",
    "matched_data = pd.read_csv(f\"{working_dir}/matched/data.csv\")\n",
    "\n",
    "# drop the 1.42 - 1.44 bin\n",
    "matched_noaccid_truth.drop(21, inplace=True)\n",
    "matched_noaccid_truth.reset_index(drop=True, inplace=True)\n",
    "matched_noaccid_fit.drop(21, inplace=True)\n",
    "matched_noaccid_fit.reset_index(drop=True, inplace=True)\n",
    "matched_noaccid_data.drop(21, inplace=True)\n",
    "matched_noaccid_data.reset_index(drop=True, inplace=True)\n",
    "matched_truth.drop(21, inplace=True)\n",
    "matched_truth.reset_index(drop=True, inplace=True)\n",
    "matched_data.drop(21, inplace=True)\n",
    "matched_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "matched_noaccid_plotter = pwa_tools.Plotter(matched_noaccid_fit, matched_noaccid_data, truth_df=matched_noaccid_truth)\n",
    "matched_plotter = pwa_tools.Plotter(matched_fit, matched_data, truth_df=matched_truth)\n",
    "\n",
    "matched_noaccid_pull = average_absolute_pull(matched_noaccid_fit, matched_noaccid_truth, [\"1p\", \"1m\"])\n",
    "matched_pull = average_absolute_pull(matched_fit, matched_truth, [\"1p\", \"1m\"])\n",
    "print(f\"{\"-\"*30}\")\n",
    "print(f\"With no background: {matched_noaccid_pull}\")\n",
    "print(f\"With out of time photons: {matched_pull}\")\n",
    "print(f\"Difference: {matched_noaccid_pull - matched_pull}\")\n",
    "print(f\"{\"-\"*30}\")\n",
    "\n",
    "matched_noaccid_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)\n",
    "matched_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noacc_fit = pd.read_csv(f\"{working_dir}/noaccidental/fit.csv\", index_col=\"index\")\n",
    "noacc_truth = pd.read_csv(f\"{working_dir}/noaccidental/truth.csv\", index_col=\"index\")\n",
    "noacc_data = pd.read_csv(f\"{working_dir}/noaccidental/data.csv\")\n",
    "\n",
    "all_fit = pd.read_csv(f\"{working_dir}/all_effects/fit.csv\", index_col=\"index\")\n",
    "all_truth = pd.read_csv(f\"{working_dir}/all_effects/truth.csv\", index_col=\"index\")\n",
    "all_data = pd.read_csv(f\"{working_dir}/all_effects/data.csv\")\n",
    "\n",
    "noacc_plotter = pwa_tools.Plotter(noacc_fit, noacc_data, truth_df=noacc_truth)\n",
    "all_plotter = pwa_tools.Plotter(all_fit, all_data, truth_df=all_truth)\n",
    "\n",
    "noacc_pull = average_absolute_pull(noacc_fit, noacc_truth, [\"1p\", \"1m\"])\n",
    "all_pull = average_absolute_pull(all_fit, all_truth, [\"1p\", \"1m\"])\n",
    "print(f\"{\"-\"*30}\")\n",
    "print(f\"With no background: {noacc_pull}\")\n",
    "print(f\"With out of time photons: {all_pull}\")\n",
    "print(f\"Difference: {noacc_pull - all_pull}\")\n",
    "print(f\"{\"-\"*30}\")\n",
    "\n",
    "noacc_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)\n",
    "all_plotter.pull_distribution([\"1p\", \"1m\"], scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
