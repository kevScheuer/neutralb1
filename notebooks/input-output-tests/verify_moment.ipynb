{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import neutralb1.utils\n",
    "\n",
    "WORKSPACE_DIR = neutralb1.utils.get_workspace_dir()\n",
    "\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=WORKSPACE_DIR).decode('utf-8').strip()\n",
    "print(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe16b6",
   "metadata": {},
   "source": [
    "**Repository Version** \n",
    "This notebook was run at commit:\n",
    "`4f209e3f781a818361126aac3d976f7fec2d7e52`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cbf86",
   "metadata": {},
   "source": [
    "# Verifying the Projection of Moments with Signal MC\n",
    "As found previously, the projected moments have some missing factors causing them not to match expectations. Since then, two major updates have occured:\n",
    "1. I've developed a direct fit to data using moments as AmpTools parameters, which should now provide a set of \"true\" values we can compare the projected moments to.\n",
    "   <br>a. Has issues in extracting moments with $>1\\%$ contribution, but this should be enough to track down factors\n",
    "2. The old python projection script has now been replaced by a c++ version, that also includes the necessary normalization integrals\n",
    "   a. The script may likely be updated over time, so check the commit hash for what version to use.\n",
    "\n",
    "This study will proceed as follows:\n",
    "1. Generate Signal Monte Carlo (MC) according to a pseudo-realistic set of waves (no acceptance effects i.e. *thrown*)\n",
    "   <br>a. 35% polarization and in the PARA_0 orientation\n",
    "2. Fit MC with same waveset, and obtain a fit result that should match the generated wave values\n",
    "3. Project moments from the fit result to obtain a projected moment-set $H_{\\text{proj}}$\n",
    "4. Fit MC with the same number of moments, and obtain a fitted moment-set $H_{\\text{fit}}$\n",
    "5. Compare the fit and projected sets to investigate the missing factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79a25",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb931c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load common libraries\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load neutralb1 libraries\n",
    "import neutralb1.utils as utils\n",
    "from neutralb1.analysis.result import ResultManager\n",
    "\n",
    "utils.load_environment()\n",
    "\n",
    "# load in useful directories as constants\n",
    "CWD = pathlib.Path.cwd()\n",
    "STUDY_DIR = f\"{WORKSPACE_DIR}/studies/input-output-tests/verify-moment\"\n",
    "TRUTH_DIR = f\"{STUDY_DIR}/data/amp_truth\"\n",
    "AMP_DIR = f\"{STUDY_DIR}/data/amplitude_results\"\n",
    "MOMENT_DIR = f\"{STUDY_DIR}/data/moment_results\"\n",
    "\n",
    "# set env variables for shell cells\n",
    "os.environ[\"WORKSPACE_DIR\"] = WORKSPACE_DIR\n",
    "os.environ['STUDY_DIR'] = STUDY_DIR\n",
    "os.environ['TRUTH_DIR'] = TRUTH_DIR\n",
    "os.environ['AMP_DIR'] = AMP_DIR\n",
    "os.environ['MOMENT_DIR'] = MOMENT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e732744",
   "metadata": {},
   "source": [
    "## Data Generation and Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d54b2d",
   "metadata": {},
   "source": [
    "### Generate\n",
    "We'll use the same cfg file to generate and fit the amplitude-based Monte Carlo with. This will be done in a single bin of mass at:\n",
    "* $0.1 < -t < 0.2$\n",
    "* $8.2 < E_\\gamma < 8.8$\n",
    "* $1.20 < M_{\\omega\\pi^0} < 1.22$\n",
    "\n",
    "The data file produced by `gen_vec_ps` is used by the fits, but only contains the simple 4-vectors and none of the histograms that we typically use for conversion to a csv file. So we must use the `gen_vec_ps_diagnostic.root` file to extract this information. This file has no information on the $E_\\gamma$ variable though, but this is okay to leave empty as we know what range we're generating / do not use it from the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b445e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat $STUDY_DIR/cfg_files/amplitudes.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "if [ -e \"${STUDY_DIR}/data/root_files/data.root\" ]; then\n",
    "    echo \"data exists, skipping generation.\"\n",
    "else \n",
    "    echo \"Generating data...\"\n",
    "    gen_vec_ps -c ${STUDY_DIR}/cfg_files/amplitudes.cfg\\\n",
    "        -o ${STUDY_DIR}/data/root_files/data.root\\\n",
    "        -l 1.20 -u 1.22\\\n",
    "        -n 50000\\\n",
    "        -a 8.2 -b 8.8\\\n",
    "        -tmin 0.1 -tmax 0.2\n",
    "    if [ -e \"${STUDY_DIR}/data/root_files/data.root\" ]; then\n",
    "        echo \"Data generation successful.\"\n",
    "    else\n",
    "        echo \"Data generation failed.\"\n",
    "        exit 1\n",
    "    fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i $STUDY_DIR/data/root_files/gen_vec_ps_diagnostic.root -o $STUDY_DIR/data/csv_files/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7e379",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a160fc5",
   "metadata": {},
   "source": [
    "#### Truth Generation\n",
    "To compare our later amplitude results to the true values, we need to perform a \"truth fit\" by fixing the production coefficients in a `.cfg` file to the same values we used to generate the MC with. Since these values are sensitive to the total number of events, we multiply all the fixed amplitudes by a common `intensity_scale` factor to adjust them properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat $STUDY_DIR/cfg_files/truth.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62da5a",
   "metadata": {},
   "source": [
    "Only a single fit needs to be performed, which we can easily do here. There's no need to produce angular distribution plots since we know they will match by construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d339ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $TRUTH_DIR\n",
    "\n",
    "# symlink to data and phasespace files\n",
    "ln -sf $STUDY_DIR/data/root_files/data.root ./data.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpace.root ./anglesOmegaPiPhaseSpace.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpaceAcc.root ./anglesOmegaPiPhaseSpaceAcc.root\n",
    "\n",
    "if [ -e ./omegapi.fit ]; then\n",
    "    echo \"Truth fit already exists, skipping.\"\n",
    "else\n",
    "    echo \"Running truth fit...\"\n",
    "    fit -c ${STUDY_DIR}/cfg_files/truth.cfg > truth_fit.log\n",
    "    if [ -e ./omegapi.fit ]; then\n",
    "        echo \"Truth fit successful.\"\n",
    "    else\n",
    "        echo \"Truth fit failed.\"        \n",
    "    fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd $TRUTH_DIR\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o $STUDY_DIR/data/csv_files/truth.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffe717",
   "metadata": {},
   "source": [
    "#### Amplitudes\n",
    "Amplitude fits will require a GPU session due to their performance requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5abf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -e \"${AMP_DIR}/omegapi.fit\" ]; then\n",
    "    echo \"Amplitude results exist, skipping fitting.\"\n",
    "else\n",
    "    echo \"Run 'fit -c ${STUDY_DIR}/cfg_files/amplitudes.cfg -m 10000000 -r 50 > amplitude_fit.log' on an interactive GPU node to fit the data.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d85dd2",
   "metadata": {},
   "source": [
    "Once fits are complete, generate files to view the angular distributions for the vecps_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${AMP_DIR}\n",
    "\n",
    "# create symlinks so the vecps_plotter can find the data/phasespace files\n",
    "ln -sf ${STUDY_DIR}/data/root_files/data.root ./data.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpace.root ./anglesOmegaPiPhaseSpace.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpaceAcc.root ./anglesOmegaPiPhaseSpaceAcc.root\n",
    "\n",
    "if [ -e ./vecps_plot.root ]; then\n",
    "    echo \"Plotter output already exists, skipping plotting.\"\n",
    "else\n",
    "    echo \"Plotting results...\"\n",
    "    vecps_plotter ./omegapi.fit\n",
    "    angle_plotter ./vecps_plot.root \"Thrown MC\" \"\" ${AMP_DIR} --gluex-style\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_pdf(f\"{AMP_DIR}/fit.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b87d7",
   "metadata": {},
   "source": [
    "Convert the fit output to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6210942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${AMP_DIR}\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o  $STUDY_DIR/data/csv_files/amplitude_result.csv\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o $STUDY_DIR/data/csv_files/projected_moments.csv --moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42b858",
   "metadata": {},
   "source": [
    "#### Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53722ec4",
   "metadata": {},
   "source": [
    "Same process as the amplitude fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ${STUDY_DIR}/cfg_files/moments.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f12c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $MOMENT_DIR\n",
    "ln -sf ${STUDY_DIR}/data/root_files/data.root ./data.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpace.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpaceAcc.root\n",
    "\n",
    "if [ -e \"./omegapi.fit\" ]; then\n",
    "    echo \"Moment results exist, skipping fitting.\"\n",
    "else\n",
    "    echo \"Run 'fit -c ${STUDY_DIR}/cfg_files/moments.cfg -m 10000000 -r 50 > moment_fit.log' on an interactive GPU node to fit the data.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${MOMENT_DIR}\n",
    "if [ -e ./vecps_plot.root ]; then\n",
    "    echo \"Plotter output already exists, skipping plotting.\"\n",
    "else\n",
    "    echo \"Plotting results...\"\n",
    "    vecps_plotter ./omegapi.fit\n",
    "    angle_plotter ./vecps_plot.root \"Thrown MC\" \"\" ${MOMENT_DIR} --gluex-style\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_pdf(f\"{MOMENT_DIR}/fit.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The error for the following command is expected, the vecPSMoment amplitude cannot be parsed into coherent sums. This is fine because the \n",
    "# moments are stored as parameters, which do get extracted.\n",
    "cd ${MOMENT_DIR}\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o  $STUDY_DIR/data/csv_files/moment_result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8483e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load in our dataframes\n",
    "data_df = pd.read_csv(f\"{STUDY_DIR}/data/csv_files/data.csv\")\n",
    "fit_results_df = pd.read_csv(f\"{STUDY_DIR}/data/csv_files/amplitude_result.csv\")\n",
    "truth_df = pd.read_csv(f\"{STUDY_DIR}/data/csv_files/truth.csv\")\n",
    "projected_moments_df = pd.read_csv(f\"{STUDY_DIR}/data/csv_files/projected_moments.csv\")\n",
    "fitted_moments_df = pd.read_csv(f\"{STUDY_DIR}/data/csv_files/moment_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c1aad",
   "metadata": {},
   "source": [
    "### Checking Amplitude Results\n",
    "We'll first want to make sure that our amplitude-based fits actually resolved to the values we generated with before we project them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_results = ResultManager(fit_results_df, data_df, truth_df=truth_df)\n",
    "amplitude_results.preprocess(linker_max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90127580",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_columns = [l for sublist in utils.get_coherent_sums(amplitude_results.fit_df).values() for l in sublist]\n",
    "phase_columns = list(set(utils.get_phase_differences(amplitude_results.fit_df).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254e4cf",
   "metadata": {},
   "source": [
    "Print the percentage uncertainty of the results to make sure we don't have errors on the same order of magnitude as the result. Negative reflectivities are quite small so some of their values may be >50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0360563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in amp_columns:\n",
    "    rel_err = (amplitude_results.fit_df[f\"{col}_err\"] / amplitude_results.fit_df[col]).iloc[0] * 100\n",
    "    if rel_err > 50:\n",
    "        print(f\"{col}: {rel_err}\")\n",
    "for col in phase_columns:    \n",
    "    rel_err = (amplitude_results.fit_df[f\"{col}_err\"] / amplitude_results.fit_df[col]).iloc[0] * 100    \n",
    "    print(f\"{col}: {rel_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7a240",
   "metadata": {},
   "source": [
    "The standardized residuals for the amplitudes will let us know if any of the coherent sums are very far outside of the range captured by the error. They are not printed for the phases, as the errors are *very* underestimated for them and thus the standardized residuals are not trustworthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in amp_columns:\n",
    "    std_res = ((amplitude_results.fit_df[col] - amplitude_results.truth_df[col]) / amplitude_results.fit_df[f\"{col}_err\"]).iloc[0]\n",
    "    if std_res > 3 or std_res < -3:\n",
    "        print(f\"{col}: {std_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0de1eb",
   "metadata": {},
   "source": [
    "### Comparing Projected to Fitted Moments\n",
    "We don't have \"truth\" moments to compare to, so we can move forward with checking how the moments projected from the amplitudes $H_{\\text{projected}}$ compare to the moments obtained by fitting them to data with AmpTools $H_{\\text{fitted}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9eaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns starting with \"H\" in both dataframes\n",
    "proj_cols = [col for col in projected_moments_df.columns if col.startswith(\"H\")]\n",
    "fit_cols = [col for col in fitted_moments_df.columns if col.startswith(\"H\") and not col.endswith(\"_err\")]\n",
    "print(proj_cols)\n",
    "print(fit_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee73f99",
   "metadata": {},
   "source": [
    "The projected moments are split into real and imaginary parts, whereas the fitted moments are forced to be one or the other. We expect the $H^0$ and $H^1$ moments to be purely real, and the $H^2$ moments to be purely imaginary. We'll make sure those values are close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_imag = [c for c in proj_cols if \"H0\" in c and \"_imag\" in c]\n",
    "H1_imag = [c for c in proj_cols if \"H1\" in c and \"_imag\" in c]\n",
    "H2_real = [c for c in proj_cols if \"H2\" in c and \"_real\" in c]\n",
    "\n",
    "print(projected_moments_df[H0_imag + H1_imag + H2_real].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"_imag\" columns for H0 and H1, and the \"_real\" columns for H2\n",
    "imag_cols_to_drop = [col for col in proj_cols if (col.startswith(\"H0\") or col.startswith(\"H1\")) and col.endswith(\"_imag\")]\n",
    "filtered_proj_moments_df = projected_moments_df.drop(columns=imag_cols_to_drop)\n",
    "real_cols_to_drop = [col for col in proj_cols if col.startswith(\"H2\") and col.endswith(\"_real\")]\n",
    "filtered_proj_moments_df = filtered_proj_moments_df.drop(columns=real_cols_to_drop)\n",
    "\n",
    "# remove the real or imag suffix\n",
    "filtered_proj_moments_df = filtered_proj_moments_df.rename(\n",
    "    columns={col: col.replace(\"_real\", \"\").replace(\"_imag\", \"\") for col in filtered_proj_moments_df.columns}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ca409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both dataframes have the same columns\n",
    "print(set(filtered_proj_moments_df.columns) - set(fitted_moments_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf89c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the ratios between the projected and fitted moments\n",
    "ratio_df = pd.DataFrame(index=filtered_proj_moments_df.index)\n",
    "moment_columns = [c for c in filtered_proj_moments_df.columns if c.startswith(\"H\")]\n",
    "ratios = []\n",
    "ratio_errs = []\n",
    "\n",
    "for col in moment_columns:\n",
    "    ratio = filtered_proj_moments_df[col] / fitted_moments_df[col]\n",
    "    # for now we'll just use the MINUIT errors from the fitted moments\n",
    "    ratio_err = ratio * np.sqrt(np.square(fitted_moments_df[f\"{col}_err\"] / fitted_moments_df[col]))\n",
    "    ratios.append(ratio)\n",
    "    ratio_errs.append(ratio_err)\n",
    "\n",
    "ratio_errs_df = pd.DataFrame(ratio_errs).T\n",
    "ratio_errs_df.columns = moment_columns\n",
    "\n",
    "# add the ratio errors to the ratio dataframe as a new row\n",
    "ratio_df = pd.concat([ratio_df, pd.DataFrame(ratios).T], axis=1)\n",
    "ratio_df = pd.concat([ratio_df, ratio_errs_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b46f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.errorbar(x=ratio_df.columns, y=ratio_df.iloc[0], yerr=abs(ratio_df.iloc[1]), marker='o', color=\"black\")\n",
    "plt.axhline(y=1, color='red', linestyle='--', label='Expected Ratio = 1')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Projected / Fitted Moment Ratio\")\n",
    "plt.xlabel(\"Moment\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
