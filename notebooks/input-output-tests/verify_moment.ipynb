{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import neutralb1.utils\n",
    "\n",
    "WORKSPACE_DIR = neutralb1.utils.get_workspace_dir()\n",
    "\n",
    "git_hash = subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=WORKSPACE_DIR).decode('utf-8').strip()\n",
    "print(git_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe16b6",
   "metadata": {},
   "source": [
    "**Repository Version** \n",
    "This notebook was run at commit:\n",
    "`FILL WHEN DONE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cbf86",
   "metadata": {},
   "source": [
    "# Verifying the Projection of Moments with Signal MC\n",
    "As found previously, the projected moments have some missing factors causing them not to match expectations. Since then, two major updates have occured:\n",
    "1. I've developed a direct fit to data using moments as AmpTools parameters, which should now provide a set of \"true\" values we can compare the projected moments to.\n",
    "   <br>a. Has issues in extracting moments with $>1\\%$ contribution, but this should be enough to track down factors\n",
    "2. The old python projection script has now been replaced by a c++ version, that also includes the necessary normalization integrals\n",
    "   a. The script may likely be updated over time, so check the commit hash for what version to use.\n",
    "\n",
    "This study will proceed as follows:\n",
    "1. Generate Signal Monte Carlo (MC) according to a pseudo-realistic set of waves (no acceptance effects i.e. *thrown*)\n",
    "   <br>a. 35% polarization and in the PARA_0 orientation\n",
    "2. Fit MC with same waveset, and obtain a fit result that should match the generated wave values\n",
    "3. Project moments from the fit result to obtain a projected moment-set $H_{\\text{proj}}$\n",
    "4. Fit MC with the same number of moments, and obtain a fitted moment-set $H_{\\text{fit}}$\n",
    "5. Compare the fit and projected sets to investigate the missing factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79a25",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb931c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load common libraries\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neutralb1.utils as utils\n",
    "from neutralb1.analysis.result import ResultManager\n",
    "\n",
    "utils.load_environment()\n",
    "\n",
    "# load in useful directories as constants\n",
    "CWD = pathlib.Path.cwd()\n",
    "STUDY_DIR = f\"{WORKSPACE_DIR}/studies/input-output-tests/verify-moment\"\n",
    "AMP_DIR = f\"{STUDY_DIR}/data/amplitude_results\"\n",
    "MOMENT_DIR = f\"{STUDY_DIR}/data/moment_results\"\n",
    "\n",
    "# set env variables for shell cells\n",
    "os.environ[\"WORKSPACE_DIR\"] = WORKSPACE_DIR\n",
    "os.environ['STUDY_DIR'] = STUDY_DIR\n",
    "os.environ['AMP_DIR'] = AMP_DIR\n",
    "os.environ['MOMENT_DIR'] = MOMENT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e732744",
   "metadata": {},
   "source": [
    "## Data Generation and Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d54b2d",
   "metadata": {},
   "source": [
    "### Generate\n",
    "We'll use the same cfg file to generate and fit the amplitude-based Monte Carlo with. This will be done in a single bin of mass at:\n",
    "* $0.1 < -t < 0.2$\n",
    "* $8.2 < E_\\gamma < 8.8$\n",
    "* $1.20 < M_{\\omega\\pi^0} < 1.22$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b445e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{STUDY_DIR}/cfg_files/amplitudes.cfg\", \"r\") as f:\n",
    "    for i in range(18):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c00d1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "if [ -e \"${STUDY_DIR}/data/root_files/data.root\" ]; then\n",
    "    echo \"data exists, skipping generation.\"\n",
    "else \n",
    "    echo \"Generating data...\"\n",
    "    gen_vec_ps -c ${STUDY_DIR}/cfg_files/amplitudes.cfg\\\n",
    "        -o ${STUDY_DIR}/data/root_files/data.root\\\n",
    "        -l 1.20 -u 1.22\\\n",
    "        -n 50000\\\n",
    "        -a 8.2 -b 8.8\\\n",
    "        -tmin 0.1 -tmax 0.2\n",
    "    if [ -e \"${STUDY_DIR}/data/root_files/data.root\" ]; then\n",
    "        echo \"Data generation successful.\"\n",
    "    else\n",
    "        echo \"Data generation failed.\"\n",
    "        exit 1\n",
    "    fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6bea6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# convert the data to CSV\n",
    "if [ -e \"${STUDY_DIR}/data/root_files/data.csv\" ]; then\n",
    "    echo \"Data CSV exists, skipping conversion.\"\n",
    "else\n",
    "    echo \"Converting data to CSV...\"\n",
    "    python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "        -i $STUDY_DIR/data/root_files/gen_vec_ps_diagnostic.root -o $STUDY_DIR/data/root_files/data.csv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7e379",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffe717",
   "metadata": {},
   "source": [
    "#### Amplitudes\n",
    "Amplitude fits will require a GPU session due to their performance requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5abf54",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -e \"${AMP_DIR}/omegapi.fit\" ]; then\n",
    "    echo \"Amplitude results exist, skipping fitting.\"\n",
    "else\n",
    "    echo \"Run 'fit -c ${STUDY_DIR}/cfg_files/amplitudes.cfg -m 10000000 -r 50 > amplitude_fit.log' on an interactive GPU node to fit the data.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d85dd2",
   "metadata": {},
   "source": [
    "Once fits are complete, generate files to view the angular distributions for the vecps_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c6ab8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${AMP_DIR}\n",
    "\n",
    "# create symlinks so the vecps_plotter can find the data/phasespace files\n",
    "ln -sf ${STUDY_DIR}/data/root_files/data.root ./data.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpace.root ./anglesOmegaPiPhaseSpace.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpaceAcc.root ./anglesOmegaPiPhaseSpaceAcc.root\n",
    "\n",
    "if [ -e ./vecps_plot.root ]; then\n",
    "    echo \"Plotter output already exists, skipping plotting.\"\n",
    "else\n",
    "    echo \"Plotting results...\"\n",
    "    vecps_plotter ./omegapi.fit\n",
    "    angle_plotter ./vecps_plot.root \"Thrown MC\" \"\" ${AMP_DIR} --gluex-style\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b87d7",
   "metadata": {},
   "source": [
    "Convert the fit output to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6210942",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${AMP_DIR}\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o result.csv\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o projected_moments.csv --moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42b858",
   "metadata": {},
   "source": [
    "#### Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53722ec4",
   "metadata": {},
   "source": [
    "Same process as the amplitude fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d35cf",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ${STUDY_DIR}/cfg_files/moments.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f12c77",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $MOMENT_DIR\n",
    "ln -sf ${STUDY_DIR}/data/root_files/data.root ./data.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpace.root\n",
    "ln -sf ${STUDY_DIR}/data/root_files/anglesOmegaPiPhaseSpaceAcc.root\n",
    "\n",
    "if [ -e \"./omegapi.fit\" ]; then\n",
    "    echo \"Moment results exist, skipping fitting.\"\n",
    "else\n",
    "    echo \"Run 'fit -c ${STUDY_DIR}/cfg_files/moments.cfg -m 10000000 -r 50 > moment_fit.log' on an interactive GPU node to fit the data.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063d748",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${MOMENT_DIR}\n",
    "if [ -e ./vecps_plot.root ]; then\n",
    "    echo \"Plotter output already exists, skipping plotting.\"\n",
    "else\n",
    "    echo \"Plotting results...\"\n",
    "    vecps_plotter ./omegapi.fit\n",
    "    angle_plotter ./vecps_plot.root \"Thrown MC\" \"\" ${MOMENT_DIR} --gluex-style\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcd8ed",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ${MOMENT_DIR}\n",
    "python $WORKSPACE_DIR/src/neutralb1/batch/convert_to_csv.py\\\n",
    "    -i omegapi.fit -o result.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8483e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load in our dataframes\n",
    "data_df = pd.read_csv(f\"{STUDY_DIR}/data/root_files/data.csv\")\n",
    "fit_results_df = pd.read_csv(f\"{AMP_DIR}/result.csv\")\n",
    "projected_moments_df = pd.read_csv(f\"{AMP_DIR}/projected_moments.csv\")\n",
    "fitted_moments_df = pd.read_csv(f\"{MOMENT_DIR}/result.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c1aad",
   "metadata": {},
   "source": [
    "### Checking Amplitude Results\n",
    "We'll first want to make sure that our amplitude-based fits actually resolved to the values we generated with before we project them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c320f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9eaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns starting with \"H\" in both dataframes\n",
    "proj_cols = [col for col in projected_moments_df.columns if col.startswith(\"H\") and not col.endswith(\"_err\")]\n",
    "fit_cols = [col for col in fitted_moments_df.columns if col.startswith(\"H\") and not col.endswith(\"_err\")]\n",
    "\n",
    "# Drop the \"_imag\" columns for H0 and H1, and the \"_real\" columns for H2\n",
    "imag_cols_to_drop = [col for col in proj_cols if (col.startswith(\"H0\") or col.startswith(\"H1\")) and col.endswith(\"_imag\")]\n",
    "filtered_proj_moments_df = projected_moments_df.drop(columns=imag_cols_to_drop)\n",
    "real_cols_to_drop = [col for col in proj_cols if col.startswith(\"H2\") and col.endswith(\"_real\")]\n",
    "filtered_proj_moments_df = filtered_proj_moments_df.drop(columns=real_cols_to_drop)\n",
    "\n",
    "# remove the real or imag suffix\n",
    "filtered_proj_moments_df = filtered_proj_moments_df.rename(\n",
    "    columns={col: col.replace(\"_real\", \"\").replace(\"_imag\", \"\") for col in filtered_proj_moments_df.columns}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ca409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of moment names\n",
    "common_moments = sorted(set(filtered_proj_moments_df.columns) & set(fit_cols))\n",
    "print(f\"Common moments: {common_moments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222bdbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ratios for each matching moment (real part only)\n",
    "for moment in common_moments:\n",
    "    proj_val = filtered_proj_moments_df[moment].iloc[0]\n",
    "    fit_val = fitted_moments_df[moment].iloc[0]\n",
    "    ratio = proj_val / fit_val if fit_val != 0 else float('nan')\n",
    "    print(f\"{moment}: projected / fitted = {proj_val:.1g} / {fit_val:.1g} \\t= {ratio:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543e5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
