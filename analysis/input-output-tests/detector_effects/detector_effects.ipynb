{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Detector Effects Break $\\omega\\pi^0$ Amplitude Analysis?\n",
    "Initial input output tests in $\\omega\\pi^0$ are showing bin-to-bin inconsistencies in fit results from an amplitude analysis. The goal of this notebook will be to determine where these inconsistencies are sourced from so that we may go about solving them. (Discussion of AmpTools efficiency calculation here)\n",
    "\n",
    "Questions: \n",
    "1. **What detector effects are most detrimental to the amplitude analysis results?**\n",
    "2. **Does the AmpTools efficiency calculation impact fit performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To test this, we will be conducting input-output tests using [$\\omega\\pi^0$ Monte Carlo signal and phasespace files.](https://halldweb.jlab.org/wiki-private/index.php/Omega_Pi_Simulation_Samples_Version_3#Neutral_signal_versionsver3.1). We'll perform the amplitude analysis in independent bins of $\\omega\\pi^0$ invariant mass, and the \"output\" fit results in each bin are compared to the generated \"input\" values we expect the fit to successfully converge to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect Options\n",
    "Through the DSelector, we have access to a wide array of options to turn on / off effects of our detector simulation. These are:\n",
    "1. **Detector Acceptance:** applies the detector efficiency to events \n",
    "2. **Reconstruction:** An algorithm uses the hits within the detector to reconstruct the particle tracks from the decay. This effectively \"smears\" the particle 4-momenta with detector resolution effects and reconstruction error\n",
    "3. **Misidentification & Combinatorics:** Allow ourselves to \"forget\" the origin and exact ID of each particle, and rely on the kinematic fitter and our cuts to do this instead.\n",
    "4. **Out-of-time photons (Oot $\\gamma$):** simulates background photon \"sidebands\" that are statistically subtracted to obtain the photon that generated the event. This option can be combined with any of the above effects\n",
    "\n",
    "By performing an amplitude analysis to datasets produced from these options, we can determine which effect is most detrimental to the fit result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Input\n",
    "(make a table of consistent cuts being applied across all bins, -t, masses, E_beam, etc)\n",
    "\n",
    "Input files are obtained by passing the Monte Carlo ROOT trees through a DSelector, using a standard set of cuts on values like the $\\chi^2_{\\text{kinfit}}$. Depending on what detector effects we include some of these cuts are turned on/off. For example, if we don't want to include out-of-time photons then we do not utilize an RF sideband subtraction, since we know for certain what photon generated the event. For each detector effect situation, we then have a data file for the entire $\\omega\\pi^0$ mass range. To obtain the files for the mass-independent fits, we copy the trees to each bin and apply cuts on the $-t$, $\\gamma_{\\text{beam}}$, and $M_{\\omega\\pi^0}$ values. Note that an extra cut is included on the invariant mass of the $p\\pi^0$ pair as well, requiring $M_{p\\pi^0} > 1.4~GeV$. This cut is applied in real data to remove the $\\Delta^+$ baryon contribution. We don't generate the $\\Delta^+$ in our MC and so do not strictly *need* this cut, but past work has indicated that leaving this cut in is not detrimental to the fit results.\n",
    "\n",
    "The data files, now portioned into bins of $\\omega\\pi^0$ mass, allow us to calculate the detector efficiency $\\eta_{\\text{data}}$ in each bin. We have a data file for the \"thrown\" case, in which no detector effects are applied, and so dividing any dataset by this tells us the efficiency of our detector:\n",
    "\n",
    "$$\\eta_{\\text{data}} = \\frac{\\text{Events}_{~\\text{gen}}}{\\text{Events}_{~\\text{detected}}}$$\n",
    "\n",
    "With the data files ready for PWA, we arrive at a problem. The \"true\" production parameters that the Monte Carlo was generated with originate from a mass-dependent fit, applied over the entire $\\omega\\pi^0$ mass range, but we need the parameter values for individual bins so that we may determine how well a fit performed. To obtain these we do the following:\n",
    "1. Create a config file that has all its amplitude parameters fixed to the generated values. Include the same fixed Breit-Wigner functions from the original mass-dependent fit in the config file as well.\n",
    "2. Perform a \"fit\" in each $\\omega\\pi^0$ mass bin with this entirely fixed config file. The Breit-Wigner function will then weight the production parameters for that particular mass bin. For example, this ensures the $b_1(1235)$ is strongest in the 1.22 - 1.24 GeV bin, but has effectively zeroed out by 2.0 GeV.\n",
    "3. Lastly the overall scaling of the production parameters is sensitive to the number of events in the original mass-dependent fit. So we introduce one free floating `scale` factor, that multiplies every amplitude in the cfg file. This allows the fit to adjust the overall scaling to match the events in each bin\n",
    "\n",
    "The additional advantage of running a fit like this, is that all the coherent sum calculations can be done using AmpTools `FitResults` class on the output `.fit` files. We can produce dataframes that allow us to plot the *true* values we generated for any amplitude, and directly evaluate our fit performance relative to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Output\n",
    "(explanation here, include that I'm grabbing the scale value from the truth fit in order to properly initialize it. Also need to discuss the efficiency we calculate from AmpTools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "As discussed, we have a wide array of combinations to choose from to simulate our detector effects. This section will go through each one of interest and produce plots to view fit results and determine relations between them and the efficiencies. Start by loading in our packages and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "parent_dir = str(Path().resolve().parents[2])\n",
    "working_dir = f\"{parent_dir}/analysis/input-output-tests/detector_effects/\"\n",
    "sys.path.insert(0, parent_dir)\n",
    "import analysis.scripts.pwa_tools as pwa_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pwa Plotter class, we'll need to quickly define some custom functions for obtaining and plotting the efficiencies and any correlation the efficiency has with amplitude pull distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in default matplotlib style\n",
    "plt.style.use(\"/w/halld-scshelf2101/kscheuer/neutralb1/analysis/scripts/pwa_plotter.mplstyle\")\n",
    "\n",
    "def get_fit_efficiency(fit_file: pd.DataFrame) -> tuple[float,float]:\n",
    "    # Get the efficiency and its error from a fit file\n",
    "    eff = fit_file[\"detected_events\"] / fit_file[\"generated_events\"]\n",
    "    eff_err = eff * np.sqrt(\n",
    "        np.square(fit_file[\"detected_events_err\"] / fit_file[\"detected_events\"]) +\n",
    "        np.square(fit_file[\"generated_events_err\"] / fit_file[\"generated_events\"])\n",
    "    )\n",
    "    return eff, eff_err\n",
    "\n",
    "def get_data_efficiency(acc_file: pd.DataFrame, gen_file: pd.DataFrame) -> tuple[float,float]:\n",
    "    # Get the efficiency and its error from a data file\n",
    "    eff = acc_file[\"bin_contents\"] / gen_file[\"bin_contents\"]\n",
    "    eff_err = eff * np.sqrt(\n",
    "        np.square(acc_file[\"bin_error\"] / acc_file[\"bin_contents\"]) +\n",
    "        np.square(gen_file[\"bin_error\"] / gen_file[\"bin_contents\"])\n",
    "    )\n",
    "    return eff, eff_err\n",
    "\n",
    "def plot_efficiency(fit_df, acc_df, gen_df):\n",
    "    # Plot efficiency as function of omega-pi0 mass\n",
    "\n",
    "    fit_eff, fit_eff_err = get_fit_efficiency(fit_df)\n",
    "    data_eff, data_eff_err = get_data_efficiency(acc_df, gen_df)\n",
    "    \n",
    "    mass_bins = gen_df[\"mass_mean\"]\n",
    "    bin_width = (gen_df[\"mass_high_edge\"] - gen_df[\"mass_low_edge\"])[0]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.errorbar(\n",
    "        x=mass_bins, y=data_eff, xerr=bin_width/2., yerr=data_eff_err,\n",
    "        marker=\".\", linestyle=\"\", color=\"black\", label=r\"$\\eta_{~\\text{data}}$\"\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        x=mass_bins, y=fit_eff, xerr=bin_width/2., yerr=fit_eff_err, \n",
    "        marker=\".\", linestyle=\"\", color=\"red\", label=r\"$\\eta_{~\\text{fit}}$\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r\"$\\omega\\pi^0$ inv. mass $(GeV)$\", loc=\"right\")\n",
    "    ax.set_ylabel(f\"Efficiency / 0.02 GeV\", loc=\"top\")\n",
    "\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def plot_jp_efficiency(fit_df, acc_df, gen_df, truth_df):\n",
    "    # Plot difference of efficiencies as function of omega-pi0 mass with JP values\n",
    "    # Essentially a copy of the mass_phase function in the pwa_tools module\n",
    "\n",
    "    # grab the efficiencies and their errors\n",
    "    fit_eff, fit_eff_err = get_fit_efficiency(fit_df)\n",
    "    data_eff, data_eff_err = get_data_efficiency(acc_df, gen_df)\n",
    "    \n",
    "    # calculate the difference between the two efficiencies with their errors\n",
    "    diff_eff = data_eff - fit_eff\n",
    "    diff_eff_err = np.sqrt(\n",
    "        np.square(data_eff_err) + np.square(fit_eff_err)\n",
    "    )\n",
    "\n",
    "    # grab the mass bins and widths\n",
    "    mass_bins = gen_df[\"mass_mean\"]\n",
    "    bin_width = (gen_df[\"mass_high_edge\"] - gen_df[\"mass_low_edge\"])[0]\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        2, 1,\n",
    "        sharex=True,\n",
    "        gridspec_kw={\"wspace\": 0.0, \"hspace\": 0.07},\n",
    "        height_ratios=[3, 1],\n",
    "    )\n",
    "\n",
    "    # ---AXS 0---\n",
    "    # plot data points\n",
    "    axs[0].errorbar(\n",
    "        x=mass_bins, y=acc_df[\"bin_contents\"], xerr=bin_width/2., yerr=acc_df[\"bin_error\"],        \n",
    "        fmt=\"k.\", label=\"MC Events\",\n",
    "    )\n",
    "    # plot fit result as gray histogram\n",
    "    axs[0].bar(\n",
    "        x=mass_bins, height=fit_df[\"detected_events\"], width=bin_width,            \n",
    "        color=\"0.1\", alpha=0.15, label=\"Fit Result\"\n",
    "    )\n",
    "    axs[0].errorbar(\n",
    "        x=mass_bins, y=fit_df[\"detected_events\"], yerr=fit_df[\"detected_events_err\"],\n",
    "        fmt=\",\", color=\"0.1\", alpha=0.2, markersize=0,\n",
    "    )\n",
    "\n",
    "    # plot the JP values, hardcoded since we know what JP are present\n",
    "    colors = matplotlib.colormaps[\"Dark2\"].colors # use the same colors as the pwa Plotter\n",
    "    axs[0].errorbar( # 1+\n",
    "        x=mass_bins, y=fit_df[\"1p\"], xerr=bin_width/2., yerr=fit_df[\"1p_err\"],\n",
    "        marker=\"o\", markersize=6, linestyle=\"\", color=colors[2], label=r\"$1^{+}$\"\n",
    "    )\n",
    "    axs[0].plot( # 1+ truth\n",
    "        mass_bins, truth_df[\"1p\"], \n",
    "        linestyle=\"-\", marker=\"\", color=colors[2],\n",
    "    )\n",
    "    axs[0].errorbar( # 1-\n",
    "        x=mass_bins, y=fit_df[\"1m\"], xerr=bin_width/2., yerr=fit_df[\"1m_err\"],\n",
    "        marker=\"s\", markersize=6, linestyle=\"\", color=colors[3], label=r\"$1^{-}$\"\n",
    "    )\n",
    "    axs[0].plot( # 1- truth\n",
    "        mass_bins, truth_df[\"1m\"], \n",
    "        linestyle=\"-\", marker=\"\", color=colors[3],\n",
    "    )\n",
    "\n",
    "\n",
    "    axs[0].set_ylabel(f\"Events / {bin_width:.3f} GeV\", loc=\"top\")\n",
    "    axs[0].set_ylim(bottom=0.0)\n",
    "\n",
    "    # ---AXS 1---\n",
    "    # plot the efficiency difference\n",
    "    axs[1].errorbar(\n",
    "        x=mass_bins, y=diff_eff, xerr=bin_width/2., yerr=diff_eff_err,\n",
    "        marker=\".\", linestyle=\"\", color=\"black\"\n",
    "    )\n",
    "    axs[1].axhline(0, color=\"black\", linestyle=\"-\")\n",
    "\n",
    "    axs[1].set_xlabel(r\"$\\omega\\pi^0$ inv. mass $(GeV)$\", loc=\"right\")\n",
    "    axs[1].set_ylabel(r\"$\\Delta \\eta$\", loc=\"center\")\n",
    "\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def plot_correlation(fit_df, acc_df, gen_df, truth_df, columns: List[str]) -> None:\n",
    "    # Plot the correlation between the efficiency difference and the pull magnitude of the columns\n",
    "\n",
    "    # check if the columns are present in the dataframes\n",
    "    for col in columns:\n",
    "        if col not in fit_df.columns:\n",
    "            print(f\"WARNING: Column {col} not present in the fit_df, exiting\")\n",
    "            return\n",
    "        if col not in truth_df.columns:\n",
    "            print(f\"WARNING: Column {col} not present in the truth_df, exiting\")\n",
    "            return\n",
    "\n",
    "    # calculate the difference between the two efficiencies\n",
    "    fit_eff, _ = get_fit_efficiency(fit_df)    \n",
    "    data_eff, _ = get_data_efficiency(acc_df, gen_df)    \n",
    "    diff_eff = data_eff - fit_eff    \n",
    "\n",
    "    if diff_eff.eq(0).all():\n",
    "        print(\"WARNING: All efficiency differences are zero, returning 0 correlation\")    \n",
    "        corr = 0 \n",
    "\n",
    "    # plot the correlation between the efficiency difference and the pull magnitude of each column\n",
    "    for col in columns:\n",
    "        pull = ((fit_df[col] - truth_df[col]) / fit_df[f\"{col}_err\"]).abs()\n",
    "\n",
    "        if np.isnan(pull).any():\n",
    "            print(f\"WARNING: NaN values in pull, skipping column {col}\")\n",
    "            continue           \n",
    "        if not diff_eff.eq(0).all():\n",
    "            corr = np.corrcoef(diff_eff, pull)[0,1]\n",
    "\n",
    "        plt.scatter(diff_eff, pull, marker=\".\", label=f\"{pwa_tools.convert_amp_name(col)}: r={corr:.3f}\")\n",
    "        \n",
    "    plt.xlabel(r\"$\\Delta \\eta$\", loc=\"right\")\n",
    "    plt.ylabel(r\"$|~\\text{pull}~|$\", loc=\"top\")\n",
    "    plt.minorticks_on()    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the thrown file, as its common to all the sections below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_data = pd.read_csv(f\"{working_dir}/thrown/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal Detector (no effects)\n",
    "TODO: Explain each of these plots, so future ones make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrown_fit = pd.read_csv(f\"{working_dir}/thrown/fit.csv\", index_col=\"index\")\n",
    "thrown_truth = pd.read_csv(f\"{working_dir}/thrown/truth.csv\", index_col=\"index\")\n",
    "# no accepted data since the thrown data is the \"accepted\" data\n",
    "\n",
    "thrown_plotter = pwa_tools.Plotter(thrown_fit, thrown_data, truth_df=thrown_truth)\n",
    "\n",
    "plot_efficiency(thrown_fit, thrown_data, thrown_data)\n",
    "plot_jp_efficiency(thrown_fit, thrown_data, thrown_data, thrown_truth)\n",
    "plot_correlation(thrown_fit, thrown_data, thrown_data, thrown_truth, [\"1p\", \"1m\"])\n",
    "\n",
    "thrown_plotter.intensities()\n",
    "thrown_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(thrown_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(thrown_fit, thrown_data, thrown_data, thrown_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_noaccid_data = pd.read_csv(f\"{working_dir}/accept_noaccidental/data.csv\")\n",
    "acc_noaccid_fit = pd.read_csv(f\"{working_dir}/accept_noaccidental/fit.csv\", index_col=\"index\")\n",
    "acc_noaccid_truth = pd.read_csv(f\"{working_dir}/accept_noaccidental/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_noaccid_plotter = pwa_tools.Plotter(acc_noaccid_fit, acc_noaccid_data, truth_df=acc_noaccid_truth)\n",
    "\n",
    "plot_efficiency(acc_noaccid_fit, acc_noaccid_data, thrown_data)\n",
    "plot_jp_efficiency(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth)\n",
    "plot_correlation(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth, [\"1p\", \"1m\"])\n",
    "\n",
    "acc_noaccid_plotter.intensities()\n",
    "acc_noaccid_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(acc_noaccid_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(acc_noaccid_fit, acc_noaccid_data, thrown_data, acc_noaccid_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Acceptance & $\\gamma_{\\text{tag}}$\n",
    "$\\gamma_{\\text{tag}}$ refers to the beam photon 4-vector being the values extracted by the tagger, and not using the generated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = pd.read_csv(f\"{working_dir}/accept/data.csv\")\n",
    "acc_fit = pd.read_csv(f\"{working_dir}/accept/fit.csv\", index_col=\"index\")\n",
    "acc_truth = pd.read_csv(f\"{working_dir}/accept/truth.csv\", index_col=\"index\")\n",
    "\n",
    "acc_plotter = pwa_tools.Plotter(acc_fit, acc_data, truth_df=acc_truth)\n",
    "\n",
    "plot_efficiency(acc_fit, acc_data, thrown_data)\n",
    "plot_jp_efficiency(acc_fit, acc_data, thrown_data, acc_truth)\n",
    "plot_correlation(acc_fit, acc_data, thrown_data, acc_truth, [\"1p\", \"1m\"])\n",
    "\n",
    "acc_plotter.intensities()\n",
    "acc_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(acc_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(acc_fit, acc_data, thrown_data, acc_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Effects *Except* $\\gamma_{\\text{tag}}$\n",
    "This includes detector acceptance, resolution from reconstruction, combinatorics / Mis-ID, but does *not* use any sideband subtraction for the beam photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noacc_fit = pd.read_csv(f\"{working_dir}/noaccidental/fit.csv\", index_col=\"index\")\n",
    "noacc_truth = pd.read_csv(f\"{working_dir}/noaccidental/truth.csv\", index_col=\"index\")\n",
    "noacc_data = pd.read_csv(f\"{working_dir}/noaccidental/data.csv\")\n",
    "\n",
    "noacc_plotter = pwa_tools.Plotter(noacc_fit, noacc_data, truth_df=noacc_truth)\n",
    "\n",
    "plot_efficiency(noacc_fit, noacc_data, thrown_data)\n",
    "plot_jp_efficiency(noacc_fit, noacc_data, thrown_data, noacc_truth)\n",
    "plot_correlation(noacc_fit, noacc_data, thrown_data, noacc_truth, [\"1p\", \"1m\"])\n",
    "noacc_plotter.intensities()\n",
    "noacc_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(noacc_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(noacc_fit, noacc_data, thrown_data, noacc_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Effects Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fit = pd.read_csv(f\"{working_dir}/all_effects/fit.csv\", index_col=\"index\")\n",
    "all_truth = pd.read_csv(f\"{working_dir}/all_effects/truth.csv\", index_col=\"index\")\n",
    "all_data = pd.read_csv(f\"{working_dir}/all_effects/data.csv\")\n",
    "\n",
    "all_effects_plotter = pwa_tools.Plotter(all_fit, all_data, truth_df=all_truth)\n",
    "\n",
    "plot_efficiency(all_fit, all_data, thrown_data)\n",
    "plot_jp_efficiency(all_fit, all_data, thrown_data, all_truth)\n",
    "plot_correlation(all_fit, all_data, thrown_data, all_truth, [\"1p\", \"1m\"])\n",
    "all_effects_plotter.intensities()\n",
    "all_effects_plotter.intensities(True, True)\n",
    "\n",
    "pos_refl_waves = [x for x in pwa_tools.get_coherent_sums(all_fit)[\"eJPmL\"] if x[-1] != \"D\" and x[0] == \"p\"]\n",
    "plot_correlation(all_fit, all_data, thrown_data, all_truth, pos_refl_waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neutralb1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
